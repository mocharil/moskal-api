{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aecf78a",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f1fd8",
   "metadata": {},
   "source": [
    "Topics dan KOL belum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15cbd40",
   "metadata": {},
   "source": [
    "## keyword trends V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81741b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:16:58.774503Z",
     "start_time": "2025-04-17T11:16:58.746274Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from utils.keyword_trends import get_keyword_trends\n",
    "result = get_keyword_trends(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    \n",
    "    language = ['Indo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2a8c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:27:50.138012Z",
     "start_time": "2025-04-17T05:27:50.111428Z"
    }
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223158e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2755e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca0d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc360e57",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## context of discussion V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0494d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:28:36.279645Z",
     "start_time": "2025-04-17T05:28:36.235043Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.context_of_disccusion import get_context_of_discussion\n",
    "result = get_context_of_discussion(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07925f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:28:39.122675Z",
     "start_time": "2025-04-17T05:28:39.107211Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667a5ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5920ffc",
   "metadata": {},
   "source": [
    "## list of mentions Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909b8c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:24:46.142578Z",
     "start_time": "2025-04-17T11:24:46.090992Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.list_of_mentions import get_mentions\n",
    "import pandas as pd\n",
    "\n",
    "# Contoh penggunaan dasar\n",
    "result = get_mentions(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    source = [\"post_created_at\",\"issue\"],\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo'],\n",
    "    page=1,\n",
    "    page_size=3000,\n",
    "    sort_type=\"relevant\",  # Sort berdasarkan viral_score\n",
    "    sort_order=\"desc\",\n",
    ")\n",
    "\n",
    "result['pagination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ec7d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T11:24:48.067773Z",
     "start_time": "2025-04-17T11:24:48.059738Z"
    },
    "code_folding": [
     21,
     49
    ]
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9115fdb5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# analysis DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081e30b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## overview X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c8340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T10:40:20.199454Z",
     "start_time": "2025-04-17T10:40:20.084438Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from utils.analysis_overview import get_social_media_matrix\n",
    "matrix = get_social_media_matrix(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\",'dan'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-04-01',\n",
    "    end_date='2025-04-10',)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff502b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0d8dc76",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## mentions by categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272099c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:45:36.121428Z",
     "start_time": "2025-04-17T08:45:36.058923Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_category_analytics.py - Script untuk mendapatkan analisis kategori dan sentimen\n",
    "\n",
    "Script ini mengambil data tentang mentions berdasarkan kategori dan sentiment berdasarkan\n",
    "kategori dari Elasticsearch untuk visualisasi.\n",
    "\"\"\"\n",
    "from utils.analysis_sentiment_mentions import get_category_analytics\n",
    "\n",
    "data= get_category_analytics(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321150ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:45:37.702530Z",
     "start_time": "2025-04-17T08:45:37.685295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f25381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:45:15.528427Z",
     "start_time": "2025-04-17T08:45:15.515683Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint({\n",
    "    \"mentions_by_category\":mentions_by_category,\n",
    "    'sentiemnt_by_category':sentiment_by_category,\n",
    "    'sentiment_breakdown':sentiment_breakdown\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021e976",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## presence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6d549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:47:36.652282Z",
     "start_time": "2025-04-17T08:47:36.555309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.presence_score import get_presence_score, format_presence_score_data\n",
    "presence_data = get_presence_score(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo'])\n",
    "\n",
    "# Format data untuk tampilan yang lebih baik\n",
    "formatted_data = format_presence_score_data(presence_data)\n",
    "\n",
    "\n",
    "formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece6998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T04:38:06.490527Z",
     "start_time": "2025-04-17T04:38:06.429218Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438f215e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T04:37:45.705193Z",
     "start_time": "2025-04-17T04:37:45.700253Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "presence_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e76c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T05:15:11.174708Z",
     "start_time": "2025-04-16T05:15:11.140661Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## most share of voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b073dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T07:22:34.500572Z",
     "start_time": "2025-04-17T07:22:34.488736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.share_of_voice import get_share_of_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9dcec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T04:43:57.180454Z",
     "start_time": "2025-04-17T04:43:57.160373Z"
    },
    "code_folding": [
     16,
     42
    ],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a80ac65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T07:22:35.422668Z",
     "start_time": "2025-04-17T07:22:35.387444Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_share_of_voice(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo'],    page=1,\n",
    "    page_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfcb1fb",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## most followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5c963",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T07:43:49.408511Z",
     "start_time": "2025-04-17T07:43:49.389139Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.most_followers import get_most_followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1159643d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T07:45:48.044686Z",
     "start_time": "2025-04-17T07:45:48.022524Z"
    },
    "code_folding": [
     16
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "most_followers.py - Script untuk mendapatkan akun dengan followers/koneksi terbanyak\n",
    "\n",
    "Script ini menganalisis data dari Elasticsearch untuk menentukan akun\n",
    "dengan jumlah followers/koneksi terbanyak yang membicarakan suatu topik,\n",
    "dengan dukungan pagination.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Literal, Optional, Union\n",
    "\n",
    "# Import utilitas dari paket utils\n",
    "from utils.es_client import get_elasticsearch_client\n",
    "from utils.es_query_builder import get_date_range\n",
    "\n",
    "def get_most_followers(\n",
    "    es_host=None,\n",
    "    es_username=None,\n",
    "    es_password=None,\n",
    "    use_ssl=False,\n",
    "    verify_certs=False,\n",
    "    ca_certs=None,\n",
    "    keywords=None,\n",
    "    search_exact_phrases=False,\n",
    "    case_sensitive=False,\n",
    "    sentiment=None,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    date_filter=\"last 30 days\",\n",
    "    custom_start_date=None,\n",
    "    custom_end_date=None,\n",
    "    channels=None,\n",
    "    importance=\"all mentions\",\n",
    "    influence_score_min=None,\n",
    "    influence_score_max=None,\n",
    "    region=None,\n",
    "    language=None,\n",
    "    domain=None,\n",
    "    limit=10,\n",
    "    page=1,\n",
    "    page_size=10,\n",
    "    include_total_count=True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Mendapatkan daftar akun dengan jumlah followers terbanyak\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    es_host : str\n",
    "        Host Elasticsearch\n",
    "    es_username : str, optional\n",
    "        Username Elasticsearch\n",
    "    es_password : str, optional\n",
    "        Password Elasticsearch\n",
    "    use_ssl : bool, optional\n",
    "        Gunakan SSL untuk koneksi\n",
    "    verify_certs : bool, optional\n",
    "        Verifikasi sertifikat SSL\n",
    "    ca_certs : str, optional\n",
    "        Path ke sertifikat CA\n",
    "    keywords : list, optional\n",
    "        Daftar keyword untuk filter\n",
    "    search_exact_phrases : bool, optional\n",
    "        Jika True, gunakan match_phrase untuk pencarian keyword, jika False gunakan match AND\n",
    "    case_sensitive : bool, optional\n",
    "        Jika True, pencarian keyword bersifat case-sensitive, jika False tidak memperhatikan huruf besar/kecil\n",
    "    sentiment : list, optional\n",
    "        Daftar sentiment ['positive', 'negative', 'neutral']\n",
    "    start_date : str, optional\n",
    "        Tanggal awal format YYYY-MM-DD\n",
    "    end_date : str, optional\n",
    "        Tanggal akhir format YYYY-MM-DD\n",
    "    date_filter : str, optional\n",
    "        Filter tanggal untuk digunakan jika start_date dan end_date tidak disediakan\n",
    "    custom_start_date : str, optional\n",
    "        Tanggal awal kustom jika date_filter adalah \"custom\"\n",
    "    custom_end_date : str, optional\n",
    "        Tanggal akhir kustom jika date_filter adalah \"custom\"\n",
    "    channels : list, optional\n",
    "        Daftar channel ['twitter', 'news', 'instagram', dll]\n",
    "    importance : str, optional\n",
    "        'important mentions' atau 'all mentions'\n",
    "    influence_score_min : float, optional\n",
    "        Skor pengaruh minimum (0-100)\n",
    "    influence_score_max : float, optional\n",
    "        Skor pengaruh maksimum (0-100)\n",
    "    region : list, optional\n",
    "        Daftar region\n",
    "    language : list, optional\n",
    "        Daftar bahasa\n",
    "    domain : list, optional\n",
    "        Daftar domain untuk filter\n",
    "    limit : int, optional\n",
    "        Jumlah total akun yang akan dianalisis (untuk keseluruhan dataset)\n",
    "    page : int, optional\n",
    "        Halaman yang akan diambil (untuk pagination)\n",
    "    page_size : int, optional\n",
    "        Jumlah item per halaman (untuk pagination)\n",
    "    include_total_count : bool, optional\n",
    "        Sertakan jumlah total akun di hasil\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict\n",
    "        Dictionary berisi daftar akun dengan jumlah followers terbanyak dengan dukungan pagination\n",
    "    \"\"\"\n",
    "    # Buat koneksi Elasticsearch\n",
    "    es = get_elasticsearch_client(\n",
    "        es_host=es_host,\n",
    "        es_username=es_username,\n",
    "        es_password=es_password,\n",
    "        use_ssl=use_ssl,\n",
    "        verify_certs=verify_certs,\n",
    "        ca_certs=ca_certs\n",
    "    )\n",
    "    \n",
    "    if not es:\n",
    "        return {\n",
    "            \"data\": [],\n",
    "            \"pagination\": {\n",
    "                \"page\": page,\n",
    "                \"page_size\": page_size,\n",
    "                \"total_pages\": 0,\n",
    "                \"total_items\": 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Definisikan semua channel yang mungkin\n",
    "    default_channels = [\"twitter\", \"linkedin\", \"reddit\", \"youtube\", \"news\"]\n",
    "    \n",
    "    # Filter channels jika disediakan\n",
    "    if channels:\n",
    "        selected_channels = [ch for ch in channels if ch in default_channels]\n",
    "    else:\n",
    "        selected_channels = default_channels\n",
    "    \n",
    "    # Mapping channel ke index Elasticsearch\n",
    "    channel_to_index = {\n",
    "        \"twitter\": \"twitter_data\",\n",
    "        \"instagram\": \"instagram_data\",\n",
    "        \"linkedin\": \"linkedin_data\",\n",
    "        \"reddit\": \"reddit_data\",\n",
    "        \"youtube\": \"youtube_data\",\n",
    "        \"tiktok\": \"tiktok_data\",\n",
    "        \"news\": \"news_data\",\n",
    "        \"blogs\": \"blogs_data\",\n",
    "        \"facebook\": \"facebook_data\",\n",
    "        \"podcasts\": \"podcasts_data\",\n",
    "        \"videos\": \"videos_data\",\n",
    "        \"web\": \"web_data\"\n",
    "    }\n",
    "    \n",
    "    # Dapatkan indeks yang akan di-query\n",
    "    indices = [channel_to_index[ch] for ch in selected_channels if ch in channel_to_index]\n",
    "    \n",
    "    if not indices:\n",
    "        print(\"Error: No valid indices\")\n",
    "        return {\n",
    "            \"data\": [],\n",
    "            \"pagination\": {\n",
    "                \"page\": page,\n",
    "                \"page_size\": page_size,\n",
    "                \"total_pages\": 0,\n",
    "                \"total_items\": 0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Dapatkan rentang tanggal jika tidak disediakan\n",
    "    if not start_date or not end_date:\n",
    "        start_date, end_date = get_date_range(\n",
    "            date_filter=date_filter,\n",
    "            custom_start_date=custom_start_date,\n",
    "            custom_end_date=custom_end_date\n",
    "        )\n",
    "    \n",
    "    # Bangun query untuk mendapatkan akun dengan followers terbanyak\n",
    "    must_conditions = [\n",
    "        {\n",
    "            \"range\": {\n",
    "                \"post_created_at\": {\n",
    "                    \"gte\": start_date,\n",
    "                    \"lte\": end_date\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Tambahkan filter keywords jika ada\n",
    "    if keywords:\n",
    "        # Konversi keywords ke list jika belum\n",
    "        keyword_list = keywords if isinstance(keywords, list) else [keywords]\n",
    "        keyword_should_conditions = []\n",
    "        \n",
    "        # Tentukan field yang akan digunakan berdasarkan case_sensitive\n",
    "        caption_field = \"post_caption.keyword\" if case_sensitive else \"post_caption\"\n",
    "        issue_field = \"issue.keyword\" if case_sensitive else \"issue\"\n",
    "        \n",
    "        if search_exact_phrases:\n",
    "            # Gunakan match_phrase untuk exact matching\n",
    "            for kw in keyword_list:\n",
    "                keyword_should_conditions.append({\"match_phrase\": {caption_field: kw}})\n",
    "                keyword_should_conditions.append({\"match_phrase\": {issue_field: kw}})\n",
    "        else:\n",
    "            # Gunakan match dengan operator AND\n",
    "            for kw in keyword_list:\n",
    "                keyword_should_conditions.append({\"match\": {caption_field: {\"query\": kw, \"operator\": \"AND\"}}})\n",
    "                keyword_should_conditions.append({\"match\": {issue_field: {\"query\": kw, \"operator\": \"AND\"}}})\n",
    "        \n",
    "        keyword_condition = {\n",
    "            \"bool\": {\n",
    "                \"should\": keyword_should_conditions,\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        }\n",
    "        must_conditions.append(keyword_condition)\n",
    "    \n",
    "    # Bangun filter untuk query\n",
    "    filter_conditions = []\n",
    "    \n",
    "    # Filter untuk sentiment\n",
    "    if sentiment:\n",
    "        sentiment_condition = {\n",
    "            \"terms\": {\n",
    "                \"sentiment\": sentiment if isinstance(sentiment, list) else [sentiment]\n",
    "            }\n",
    "        }\n",
    "        filter_conditions.append(sentiment_condition)\n",
    "    \n",
    "    # Filter untuk importance\n",
    "    if importance == \"important mentions\":\n",
    "        filter_conditions.append({\n",
    "            \"range\": {\n",
    "                \"influence_score\": {\n",
    "                    \"gt\": 50\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "        \n",
    "    # Filter untuk influence score\n",
    "    if influence_score_min is not None or influence_score_max is not None:\n",
    "        influence_condition = {\"range\": {\"influence_score\": {}}}\n",
    "        if influence_score_min is not None:\n",
    "            influence_condition[\"range\"][\"influence_score\"][\"gte\"] = influence_score_min\n",
    "        if influence_score_max is not None:\n",
    "            influence_condition[\"range\"][\"influence_score\"][\"lte\"] = influence_score_max\n",
    "        filter_conditions.append(influence_condition)\n",
    "        \n",
    "    # Filter untuk region menggunakan wildcard\n",
    "    if region:\n",
    "        region_conditions = []\n",
    "        region_list = region if isinstance(region, list) else [region]\n",
    "        \n",
    "        for r in region_list:\n",
    "            region_conditions.append({\"wildcard\": {\"region\": f\"*{r}*\"}})\n",
    "        \n",
    "        region_filter = {\n",
    "            \"bool\": {\n",
    "                \"should\": region_conditions,\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        }\n",
    "        filter_conditions.append(region_filter)\n",
    "        \n",
    "    # Filter untuk language menggunakan wildcard\n",
    "    if language:\n",
    "        language_conditions = []\n",
    "        language_list = language if isinstance(language, list) else [language]\n",
    "        \n",
    "        for l in language_list:\n",
    "            language_conditions.append({\"wildcard\": {\"language\": f\"*{l}*\"}})\n",
    "        \n",
    "        language_filter = {\n",
    "            \"bool\": {\n",
    "                \"should\": language_conditions,\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        }\n",
    "        filter_conditions.append(language_filter)\n",
    "        \n",
    "    # Filter untuk domain\n",
    "    if domain:\n",
    "        domain_condition = {\n",
    "            \"bool\": {\n",
    "                \"should\": [{\"wildcard\": {\"link_post\": f\"*{d}*\"}} for d in (domain if isinstance(domain, list) else [domain])],\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        }\n",
    "        filter_conditions.append(domain_condition)\n",
    "    \n",
    "    # Gabungkan semua kondisi ke dalam query utama\n",
    "    query = {\n",
    "        \"size\": 0,  # Kita hanya perlu agregasi\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": must_conditions\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"by_channel\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"channel\",\n",
    "                    \"size\": len(selected_channels)\n",
    "                },\n",
    "                \"aggs\": {\n",
    "                    \"by_username\": {\n",
    "                        \"terms\": {\n",
    "                            \"field\": \"username\",\n",
    "                            \"size\": limit\n",
    "                        },\n",
    "                        \"aggs\": {\n",
    "                            \"subscribers\": {\n",
    "                                \"max\": {\n",
    "                                    \"field\": \"subscriber\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"followers\": {\n",
    "                                \"max\": {\n",
    "                                    \"field\": \"user_followers\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"connections\": {\n",
    "                                \"max\": {\n",
    "                                    \"field\": \"user_connections\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"influence_score\": {\n",
    "                                \"avg\": {\n",
    "                                    \"field\": \"user_influence_score\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"total_reach\": {\n",
    "                                \"sum\": {\n",
    "                                    \"field\": \"reach_score\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"total_mentions\": {\n",
    "                \"value_count\": {\n",
    "                    \"field\": \"link_post\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Tambahkan filter jika ada\n",
    "    if filter_conditions:\n",
    "        query[\"query\"][\"bool\"][\"filter\"] = filter_conditions\n",
    "    \n",
    "    \n",
    "    print(query)\n",
    "    try:\n",
    "        # Jalankan query\n",
    "        response = es.search(\n",
    "            index=\",\".join(indices),\n",
    "            body=query\n",
    "        )\n",
    "        \n",
    "        # Proses hasil untuk mendapatkan akun dengan followers terbanyak\n",
    "        channel_buckets = response[\"aggregations\"][\"by_channel\"][\"buckets\"]\n",
    "        total_mentions = response[\"aggregations\"][\"total_mentions\"][\"value\"]\n",
    "        \n",
    "        # Kumpulkan data dari semua channel\n",
    "        followers_data = []\n",
    "        \n",
    "        for channel_bucket in channel_buckets:\n",
    "            channel = channel_bucket[\"key\"]\n",
    "            username_buckets = channel_bucket[\"by_username\"][\"buckets\"]\n",
    "            \n",
    "            for username_bucket in username_buckets:\n",
    "                username = username_bucket[\"key\"]\n",
    "                mentions = username_bucket[\"doc_count\"]\n",
    "                subscribers = username_bucket[\"subscribers\"][\"value\"]\n",
    "                followers = username_bucket[\"followers\"][\"value\"]\n",
    "                connections = username_bucket[\"connections\"][\"value\"]\n",
    "                influence_score = username_bucket[\"influence_score\"][\"value\"] or 0\n",
    "                reach = username_bucket[\"total_reach\"][\"value\"]\n",
    "                \n",
    "                followers_data.append({\n",
    "                    \"channel\": channel,\n",
    "                    \"username\": username,\n",
    "                    \"followers\": followers or connections or subscribers or 0,\n",
    "                    \"influence_score\": influence_score,\n",
    "                    \"total_mentions\": mentions,\n",
    "                    \"total_reach\": reach\n",
    "                })\n",
    "        \n",
    "        \n",
    "        print(followers_data)\n",
    "        # Sortir berdasarkan jumlah followers\n",
    "        followers_data.sort(key=lambda x: x[\"followers\"], reverse=True)\n",
    "        \n",
    "        # Pagination\n",
    "        total_items = len(followers_data)\n",
    "        total_pages = (total_items + page_size - 1) // page_size  # ceiling division\n",
    "        \n",
    "        start_index = (page - 1) * page_size\n",
    "        end_index = min(start_index + page_size, total_items)\n",
    "        \n",
    "        paginated_data = followers_data[start_index:end_index]\n",
    "        \n",
    "        # Format username\n",
    "        for item in paginated_data:\n",
    "            if item[\"channel\"] == \"twitter\" and not item[\"username\"].startswith(\"@\"):\n",
    "                item[\"username\"] = f\"@{item['username']}\"\n",
    "        \n",
    "        # Buat hasil dengan informasi pagination\n",
    "        result = {\n",
    "            \"data\": paginated_data,\n",
    "            \"pagination\": {\n",
    "                \"page\": page,\n",
    "                \"page_size\": page_size,\n",
    "                \"total_pages\": total_pages,\n",
    "                \"total_items\": total_items\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Tambahkan daftar channel yang digunakan\n",
    "        result[\"channels\"] = selected_channels\n",
    "        \n",
    "        # Tambahkan total mentions keseluruhan jika diminta\n",
    "        if include_total_count:\n",
    "            result[\"total_mentions\"] = total_mentions\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Elasticsearch: {e}\")\n",
    "        return {\n",
    "            \"data\": [],\n",
    "            \"pagination\": {\n",
    "                \"page\": page,\n",
    "                \"page_size\": page_size,\n",
    "                \"total_pages\": 0,\n",
    "                \"total_items\": 0\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b12ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T07:45:48.589233Z",
     "start_time": "2025-04-17T07:45:48.522116Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_most_followers(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-21',\n",
    "    end_date='2025-04-30',\n",
    "    influence_score_max = 10,\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo'],    page=1,\n",
    "    page_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf790f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8f96f2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## trending hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f0d43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:53:19.070408Z",
     "start_time": "2025-04-17T08:53:18.992762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.trending_hashtags import get_trending_hashtags\n",
    "results = get_trending_hashtags(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "   page=1,\n",
    "    page_size=5)\n",
    "\n",
    "# Display pagination info\n",
    "print(f\"Showing page {results['pagination']['page']} of {results['pagination']['total_pages']}\")\n",
    "print(f\"Total hashtags found: {results['pagination']['total_items']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e811a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## trending links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da326bf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T06:52:25.282384Z",
     "start_time": "2025-04-16T06:52:24.884484Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.trending_links import get_trending_links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ba083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T04:56:03.231977Z",
     "start_time": "2025-04-17T04:56:03.175531Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da685109",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T04:56:03.616692Z",
     "start_time": "2025-04-17T04:56:03.518361Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_trending_links(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo'],    page=1,\n",
    "    page_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd48e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98108a3d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce838352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T06:50:21.228378Z",
     "start_time": "2025-04-16T06:50:21.216129Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## popular emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3d87f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:16:34.651513Z",
     "start_time": "2025-04-16T07:16:34.498486Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.popular_emojis import get_popular_emojis\n",
    "\n",
    "# Get top emojis from Twitter content\n",
    "emojis = get_popular_emojis(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[\"ruu tni\"],\n",
    "    channels=[\"twitter\",\"youtube\",'news','reddit'],\n",
    "    page=1,\n",
    "    page_size=50\n",
    ")\n",
    "\n",
    "emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007212e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T04:58:49.239498Z",
     "start_time": "2025-04-17T04:58:49.214744Z"
    },
    "code_folding": [
     17,
     65,
     91
    ],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881ad75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T04:58:58.310464Z",
     "start_time": "2025-04-17T04:58:58.066456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_popular_emojis(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo'],    page=1,\n",
    "    page_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa596a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714c1c1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15408e25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:45:45.468884Z",
     "start_time": "2025-04-16T07:45:45.346504Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.analysis_overview import get_social_media_matrix\n",
    "matrix = get_social_media_matrix(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[\"prabowo danantara\", \"dan\"],\n",
    "    start_date=\"2025-04-01\",\n",
    "    end_date=\"2025-04-02\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb52e5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T07:45:48.478448Z",
     "start_time": "2025-04-16T07:45:48.458423Z"
    },
    "hidden": true
   },
   "source": [
    "## stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687cac13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:43:57.433068Z",
     "start_time": "2025-04-16T09:43:57.350271Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.summary_stats import get_stats_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b84970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:03:36.568355Z",
     "start_time": "2025-04-17T05:03:36.523711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_stats_summary(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d8e7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a105aadd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aaf932",
   "metadata": {
    "hidden": true
   },
   "source": [
    "sama seperti sebelumnya, tapi yg dimasukin adalah list issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c109f8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## sentiment description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf924e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T10:03:57.948660Z",
     "start_time": "2025-04-17T10:03:57.780940Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.list_of_mentions import get_mentions\n",
    "import pandas as pd\n",
    "\n",
    "# Contoh penggunaan dasar\n",
    "post_positive = get_mentions(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    language = ['Indo'],\n",
    "    page=1,\n",
    "    page_size=50,\n",
    "    sentiment = ['positive'],\n",
    "    source = [\"post_caption\"],\n",
    "    sort_type=\"viral_score\",  # Sort berdasarkan viral_score\n",
    "    sort_order=\"desc\",\n",
    ")\n",
    "\n",
    "post_negative = get_mentions(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    language = ['Indo'],\n",
    "    page=1,\n",
    "    page_size=50,\n",
    "    sentiment = ['negative'],\n",
    "    source = [\"post_caption\"],\n",
    "    sort_type=\"viral_score\",  # Sort berdasarkan viral_score\n",
    "    sort_order=\"desc\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b5ebbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T10:15:54.284202Z",
     "start_time": "2025-04-17T10:15:54.273169Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.list_of_mentions import get_mentions\n",
    "from utils.gemini import call_gemini\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "def get_topics_sentiment_analysis(\n",
    "    es_host=None,\n",
    "    es_username=None,\n",
    "    es_password=None,\n",
    "    use_ssl=False,\n",
    "    verify_certs=False,\n",
    "    ca_certs=None,\n",
    "    keywords=None,\n",
    "    search_exact_phrases=False,\n",
    "    case_sensitive=False,\n",
    "    sentiment=None,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    date_filter=\"last 30 days\",\n",
    "    custom_start_date=None,\n",
    "    custom_end_date=None,\n",
    "    channels=None,\n",
    "    importance=\"all mentions\",\n",
    "    influence_score_min=None,\n",
    "    influence_score_max=None,\n",
    "    region=None,\n",
    "    language=None,\n",
    "    domain=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Mengambil analisis topik berdasarkan sentimen (positif dan negatif) \n",
    "    menggunakan model Gemini untuk menganalisis konten.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary berisi rangkuman topik positif dan negatif:\n",
    "        {\n",
    "            'positive_topics': \"...\",\n",
    "            'negative_topics': \"...\"\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Mendapatkan post positif\n",
    "    post_positive = get_mentions(\n",
    "        es_host=es_host,\n",
    "        es_username=es_username,\n",
    "        es_password=es_password,\n",
    "        use_ssl=use_ssl,\n",
    "        verify_certs=verify_certs,\n",
    "        ca_certs=ca_certs,\n",
    "        keywords=keywords,\n",
    "        search_exact_phrases=search_exact_phrases,\n",
    "        case_sensitive=case_sensitive,\n",
    "        sentiment=['positive'],\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        date_filter=date_filter,\n",
    "        custom_start_date=custom_start_date,\n",
    "        custom_end_date=custom_end_date,\n",
    "        channels=channels,\n",
    "        importance=importance,\n",
    "        influence_score_min=influence_score_min,\n",
    "        influence_score_max=influence_score_max,\n",
    "        region=region,\n",
    "        language=language,\n",
    "        domain=domain,\n",
    "        sort_type=\"viral_score\",  # Sort berdasarkan viral_score\n",
    "        sort_order=\"desc\",\n",
    "    page=1,\n",
    "    page_size=50\n",
    "    )\n",
    "\n",
    "    # Mendapatkan post negatif\n",
    "    post_negative = get_mentions(\n",
    "        es_host=es_host,\n",
    "        es_username=es_username,\n",
    "        es_password=es_password,\n",
    "        use_ssl=use_ssl,\n",
    "        verify_certs=verify_certs,\n",
    "        ca_certs=ca_certs,\n",
    "        keywords=keywords,\n",
    "        search_exact_phrases=search_exact_phrases,\n",
    "        case_sensitive=case_sensitive,\n",
    "        sentiment=['negative'],\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        date_filter=date_filter,\n",
    "        custom_start_date=custom_start_date,\n",
    "        custom_end_date=custom_end_date,\n",
    "        channels=channels,\n",
    "        importance=importance,\n",
    "        influence_score_min=influence_score_min,\n",
    "        influence_score_max=influence_score_max,\n",
    "        region=region,\n",
    "        language=language,\n",
    "        domain=domain,\n",
    "        sort_type=\"viral_score\",  # Sort berdasarkan viral_score\n",
    "        sort_order=\"desc\",\n",
    "        page=1,\n",
    "    page_size=50\n",
    "    )\n",
    "\n",
    "    # Menyusun prompt untuk Gemini\n",
    "    prompt = f\"\"\"You are a Social Media Analyst Expert. Your task is to analyze and summarize the content based on the list of social media posts provided below. The posts are divided into two categories based on sentiment:\n",
    "\n",
    "    POSITIVE POSTS\n",
    "    {post_positive['data']}\n",
    "\n",
    "    NEGATIVE POSTS\n",
    "    {post_negative['data']}\n",
    "\n",
    "    OUTPUT (in JSON format):\n",
    "    {{\n",
    "      \"positive_topics\": \"<Provide a concise summary (2–3 sentences) that captures the key topics or themes discussed in the positive posts.>\",\n",
    "      \"negative_topics\": \"<Provide a concise summary (2–3 sentences) that captures the key topics or concerns raised in the negative posts.>\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Memanggil Gemini API\n",
    "    prediction = call_gemini(prompt)\n",
    "    \n",
    "    try:\n",
    "        # Mencoba parse JSON dari respons\n",
    "        json_result = re.findall(r'\\{.*\\}', prediction, flags=re.I|re.S)[0]\n",
    "        return json.loads(json_result)\n",
    "    except (json.JSONDecodeError, IndexError) as e:\n",
    "        # Menangani error parsing\n",
    "        return {\n",
    "            \"positive_topics\": \"Error analyzing positive topics.\",\n",
    "            \"negative_topics\": \"Error analyzing negative topics.\",\n",
    "            \"error\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3359e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T10:16:05.886141Z",
     "start_time": "2025-04-17T10:16:01.293707Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_topics_sentiment_analysis( es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    language = ['Indo']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f591e0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e09635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:59:57.087681Z",
     "start_time": "2025-04-16T09:59:57.046298Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.keyword_trends import get_keyword_trends\n",
    "get_keyword_trends(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    language = ['Indo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2069f158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:59:59.492179Z",
     "start_time": "2025-04-16T09:59:59.474909Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62d8be",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## channel shares and sentiment overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85509d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:04:42.292798Z",
     "start_time": "2025-04-17T05:04:42.242243Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_category_analytics.py - Script untuk mendapatkan analisis kategori dan sentimen\n",
    "\n",
    "Script ini mengambil data tentang mentions berdasarkan kategori dan sentiment berdasarkan\n",
    "kategori dari Elasticsearch untuk visualisasi.\n",
    "\"\"\"\n",
    "from utils.analysis_sentiment_mentions import get_category_analytics\n",
    "\n",
    "channel_shares, _ ,sentiment_breakdown = get_category_analytics(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[\"prabowo danantara\", \"gibran\"],\n",
    "    start_date=\"2025-03-18\",\n",
    "    end_date=\"2025-04-18\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe13d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T05:04:42.822090Z",
     "start_time": "2025-04-17T05:04:42.816568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "channel_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c66c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:02:40.488684Z",
     "start_time": "2025-04-16T10:02:40.473506Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentiment_breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff52f6a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## emotion, intent and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47299c8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:56:51.701972Z",
     "start_time": "2025-04-17T08:56:51.387559Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.intent_emotions_region import get_intents_emotions_region_share\n",
    "analysis = get_intents_emotions_region_share(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[\"gibran\"],\n",
    "    date_filter=\"last 100 days\"\n",
    ")\n",
    "\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f4d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T07:36:28.154966Z",
     "start_time": "2025-04-17T07:36:28.097335Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_intents_emotions_region_share(\n",
    "    es_host=\"http://localhost:9200\",\n",
    "    keywords=[ \"prabowo\"],\n",
    "    channels=[\"twitter\",'youtube'],\n",
    "    search_exact_phrases = False,\n",
    "    case_sensitive = False,\n",
    "    date_filter = 'yesterday',\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-04-01',\n",
    "    influence_score_max = 10,\n",
    "    region = ['Maluku'],\n",
    "    language = ['Indo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e5092",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393bd7fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc79bec1",
   "metadata": {},
   "source": [
    "# TOPICCCCCCCCCCCCCCCCCCCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b1d13",
   "metadata": {},
   "source": [
    "## scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7c120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:27:16.155527Z",
     "start_time": "2025-04-17T15:27:04.881264Z"
    },
    "code_folding": [
     13
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from utils.gemini import call_gemini\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Union, Any, Optional\n",
    "\n",
    "# Hitung tanggal 120 hari ke belakang dari sekarang\n",
    "current_date = datetime.now()\n",
    "date_120_days_ago = current_date - timedelta(days=30)\n",
    "# Format tanggal ke format ISO 8601 yang kompatibel dengan Elasticsearch\n",
    "date_120_days_ago_str = date_120_days_ago.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#!pip install mysql-connector-python\n",
    "db_host = \"34.101.146.213\"\n",
    "db_port = 3306\n",
    "db_user = \"arilindra21\"\n",
    "db_password = \"sukabumi030495\"\n",
    "db_name = \"auth_api_db\"\n",
    "       \n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "class About_MySQL:\n",
    "    def __init__(self, db_host, db_port, db_user, db_password, db_name):\n",
    "        # Membuat URL koneksi dengan format SQLAlchemy\n",
    "        self.database_url = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "        \n",
    "        # Membuat engine SQLAlchemy\n",
    "        self.engine = create_engine(self.database_url)\n",
    "\n",
    "    def to_pull_data(self, query):\n",
    "        # Mengambil data menggunakan query yang diberikan dan mengonversinya ke DataFrame\n",
    "        with self.engine.connect() as connection:\n",
    "            # Menjalankan query dan mengonversi hasilnya ke DataFrame\n",
    "            df = pd.read_sql(text(query), connection)\n",
    "        return df\n",
    "    \n",
    "    def to_push_data(self, dataframe: pd.DataFrame, table_name: str, if_exist: str = 'replace'):\n",
    "        \"\"\"\n",
    "        Menyimpan DataFrame ke tabel MySQL.\n",
    "        \n",
    "        Parameters:\n",
    "        - dataframe: pd.DataFrame yang akan disimpan\n",
    "        - table_name: nama tabel tujuan\n",
    "        - if_exist: 'replace' untuk mengganti tabel, 'append' untuk menambahkan data\n",
    "        \"\"\"\n",
    "        assert if_exist in ['replace', 'append'], \"Parameter 'if_exist' harus 'replace' atau 'append'\"\n",
    "        \n",
    "        dataframe.to_sql(\n",
    "            name=table_name,\n",
    "            con=self.engine,\n",
    "            if_exists=if_exist,\n",
    "            index=False,\n",
    "            method='multi'\n",
    "        )\n",
    "        print(f\"✅ Data berhasil dipush ke tabel `{table_name}` dengan mode `{if_exist}`.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6dfeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:26:34.626466Z",
     "start_time": "2025-04-17T15:26:34.586950Z"
    },
    "code_folding": [
     1,
     50,
     64,
     79,
     121,
     162,
     196,
     248,
     447
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ingest_to_elasticsearch(data: Union[Dict[str, Any], List[Dict[str, Any]]],\n",
    "                           hosts: Union[str, List[str]] = 'http://localhost:9200',\n",
    "                           index: str = 'my_index',\n",
    "                           bulk_size: int = 1000,\n",
    "                           id_field: Optional[str] = None,\n",
    "                           **es_kwargs) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ingest data into Elasticsearch using the official Elasticsearch Python client\n",
    "    \n",
    "    Args:\n",
    "        data: Single document (dict) or list of documents to ingest\n",
    "        hosts: Elasticsearch host URL or list of hosts\n",
    "        index: Name of the index\n",
    "        bulk_size: Number of documents to send in each bulk request\n",
    "        id_field: Field to use as document ID\n",
    "        es_kwargs: Additional keyword arguments for Elasticsearch client\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with statistics about the bulk operation\n",
    "    \"\"\"\n",
    "    # Initialize Elasticsearch client\n",
    "    es = Elasticsearch(hosts=hosts, **es_kwargs)\n",
    "    \n",
    "    # Convert single document to list if needed\n",
    "    documents = data if isinstance(data, list) else [data]\n",
    "    \n",
    "    # Prepare documents for bulk operation\n",
    "    actions = []\n",
    "    for doc in documents:\n",
    "        action = {\n",
    "            \"_index\": index,\n",
    "            \"_source\": doc\n",
    "        }\n",
    "        \n",
    "        # Add document ID if provided\n",
    "        if id_field and id_field in doc:\n",
    "            action[\"_id\"] = doc[id_field]\n",
    "            \n",
    "        actions.append(action)\n",
    "    \n",
    "    # Execute bulk operation\n",
    "    result = helpers.bulk(es, actions, chunk_size=bulk_size)\n",
    "    \n",
    "    return {\n",
    "        \"success_count\": result[0],\n",
    "        \"error_count\": result[1],\n",
    "        \"total_documents\": len(documents)\n",
    "    }\n",
    "\n",
    "def chunk_list(data: List, chunk_size: int) -> List[List]:\n",
    "    \"\"\"\n",
    "    Membagi list menjadi beberapa chunk berdasarkan ukuran yang diberikan.\n",
    "\n",
    "    Parameters:\n",
    "    - data: List yang akan dibagi\n",
    "    - chunk_size: Ukuran setiap chunk\n",
    "\n",
    "    Returns:\n",
    "    - List yang berisi chunk-chunk dari list\n",
    "    \"\"\"\n",
    "    # Membagi list data menjadi chunk sesuai dengan ukuran chunk_size\n",
    "    return [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "def chunk_dataframe(df: pd.DataFrame, chunk_size: int) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Membagi DataFrame menjadi beberapa chunk berdasarkan ukuran yang diberikan.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame yang akan dibagi\n",
    "    - chunk_size: Ukuran setiap chunk (baris)\n",
    "\n",
    "    Returns:\n",
    "    - List yang berisi DataFrame chunked\n",
    "    \"\"\"\n",
    "    # Menghitung jumlah chunk yang dibutuhkan\n",
    "    chunked_data = [df.iloc[i:i + chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "    return chunked_data\n",
    "\n",
    "class ElasticsearchHelper:\n",
    "    def __init__(self, host: str):\n",
    "        self.host = host\n",
    "        self.es = self.connect()\n",
    "\n",
    "    def connect(self) -> Elasticsearch:\n",
    "        \"\"\"Membuat koneksi ke Elasticsearch.\"\"\"\n",
    "        try:\n",
    "            es = Elasticsearch(\n",
    "                self.host,\n",
    "                verify_certs=False  # Hanya untuk development, non-TLS\n",
    "            )\n",
    "            return es\n",
    "        except ElasticsearchException as e:\n",
    "            print(f\"Failed to connect to Elasticsearch: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_data(self, index: str, query: dict, size: int = 1000) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Tarik data dari Elasticsearch dengan scan helpers untuk data besar\"\"\"\n",
    "        try:\n",
    "            if not self.es:\n",
    "                raise ConnectionError(\"Tidak dapat terkoneksi dengan Elasticsearch.\")\n",
    "            \n",
    "            # Gunakan helpers.scan untuk menarik data besar\n",
    "            scan_response = helpers.scan(\n",
    "                client=self.es,\n",
    "                index=index,\n",
    "                query=query,\n",
    "                size=size,\n",
    "                scroll=\"2m\"  # Menggunakan scroll selama 2 menit untuk mengambil data\n",
    "            )\n",
    "\n",
    "            # Ambil hasil dari scan\n",
    "            all_hits = [doc[\"_source\"] for doc in scan_response]\n",
    "\n",
    "            return all_hits\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error umum: {e}\")\n",
    "            return []\n",
    "        \n",
    "def get_relevan_data(keywords):\n",
    "    es_helper = ElasticsearchHelper(host=\"http://localhost:9200\")\n",
    "    query = {\n",
    "        \"_source\": [\"issue\", \"post_caption\", \"reach_score\", \"viral_score\", \"sentiment\", \"link_post\", \"channel\"],\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"post_caption\": {\n",
    "                                \"query\": keyword,\n",
    "                                \"operator\": \"and\"  # Semua kata dalam keyword harus ada\n",
    "                            }\n",
    "                        }\n",
    "                    } for keyword in keywords\n",
    "                ],\n",
    "              \"must\": [\n",
    "                            {\n",
    "                                \"range\": {\n",
    "                                    \"post_created_at\": {\n",
    "                                        \"gte\": date_120_days_ago_str,  # Greater than or equal to 120 hari yang lalu\n",
    "                                        \"lte\": current_date.strftime(\"%Y-%m-%d %H:%M:%S\")  # Less than or equal to sekarang\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                \"must_not\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"issue\": \"Not Specified\"  # Filter: 'issue' tidak boleh \"Not Specified\"\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"minimum_should_match\": 1  # Minimal satu keyword yang cocok\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return es_helper.fetch_data(index=\"twitter_data,linkedin_data,news_data,reddit_data,youtube_data\",\n",
    "                                query=query, size=10000)\n",
    "    \n",
    "def get_df_issue(df):\n",
    "    issue_total_posts = df.groupby('issue').size().reset_index(name='total_posts')\n",
    "\n",
    "    # Hitung sum viral_score dan reach_score per issue\n",
    "    issue_scores = df.groupby('issue').agg({\n",
    "        'viral_score': 'sum',\n",
    "        'reach_score': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Hitung total per jenis sentiment per issue\n",
    "    sentiment_counts = pd.crosstab(df['issue'], df['sentiment']).reset_index()\n",
    "\n",
    "    # 2. Gabungkan semua metrik\n",
    "    result = issue_total_posts.merge(issue_scores, on='issue')\n",
    "    result = result.merge(sentiment_counts, on='issue')\n",
    "\n",
    "    # 3. Buat fungsi untuk memastikan semua jenis sentiment ada (termasuk jika nilai 0)\n",
    "    def ensure_sentiment_columns(df, sentiments=['positive', 'negative', 'neutral']):\n",
    "        for sentiment in sentiments:\n",
    "            if sentiment not in df.columns:\n",
    "                df[sentiment] = 0\n",
    "        return df\n",
    "\n",
    "    result = ensure_sentiment_columns(result)\n",
    "\n",
    "    # 4. Sorting berdasarkan viral_score (optional, bisa diubah sesuai kebutuhan)\n",
    "    result = result.sort_values(by='viral_score', ascending=False)\n",
    "\n",
    "    # 5. Reset index\n",
    "    df_issue = result.reset_index(drop=True).reset_index()\n",
    "\n",
    "    # Tampilkan hasil\n",
    "    return df_issue\n",
    "\n",
    "def get_central_issue(data_chunk):\n",
    "    issue_list = []\n",
    "    for idx, row in data_chunk.iterrows():\n",
    "        issue_list.append({\"id\": row['index'], \"issue\": row['issue']})\n",
    "\n",
    "    # Buat prompt yang lebih terstruktur dan eksplisit\n",
    "    prompt = f\"\"\"\n",
    "    Kamu adalah Media Social Analyst Expert dengan keahlian khusus dalam pengelompokan tematik.\n",
    "\n",
    "    # TUGAS\n",
    "    Analisis dan kelompokkan list issue sosial media di bawah ini menjadi kelompok-kelompok tematik.\n",
    "\n",
    "    # INSTRUKSI PENTING\n",
    "    1. Setiap issue ID hanya boleh masuk ke dalam SATU kelompok (mutually exclusive).\n",
    "    2. Hindari tumpang tindih issue di antara kelompok-kelompok.\n",
    "    3. Fokus pada tema/topik utama dari setiap issue.\n",
    "    4. Buat nama kelompok yang singkat, jelas, dan mencerminkan tema utama.\n",
    "    5. Berikan deskripsi kelompok yang informatif dan komprehensif.\n",
    "\n",
    "    # LIST ISSUE\n",
    "    ```\n",
    "    {issue_list}\n",
    "    ```\n",
    "\n",
    "    # FORMAT OUTPUT\n",
    "    Kembalikan hasil pengelompokan dalam format JSON yang tepat berikut ini:\n",
    "    ```\n",
    "    [\n",
    "      {{\n",
    "        \"unified_issue\": \"Nama Issue Kelompok 1\",\n",
    "        \"description\": \"Deskripsi ringkas tentang tema kelompok ini\",\n",
    "        \"list_issue_id\": [1, 5, 10, 15] // Daftar ID yang masuk dalam kelompok ini\n",
    "      }},\n",
    "      {{\n",
    "        \"unified_issue\": \"Nama Issue Kelompok 2\",\n",
    "        \"description\": \"Deskripsi ringkas tentang tema kelompok ini\",\n",
    "        \"list_issue_id\": [2, 6, 11, 16] // Daftar ID yang masuk dalam kelompok ini\n",
    "      }},\n",
    "      ...\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    # PARAMETER KUALITAS\n",
    "    - Setiap kelompok sebaiknya memiliki minimal 2 issue\n",
    "    - Kelompokkan berdasarkan kemiripan tema/topik dan keywords, bukan sentimen\n",
    "\n",
    "    Berikan hasil pengelompokan dalam format JSON murni tanpa komentar atau penjelasan tambahan.\n",
    "    \"\"\"\n",
    "\n",
    "    centrality = call_gemini(prompt)\n",
    "    return pd.DataFrame(eval(re.findall(r'\\[.*\\]',centrality, flags=re.I|re.S)[0]))\n",
    "\n",
    "def get_topics_overview(keywords):\n",
    "    #mendapatkan raw data\n",
    "    df = pd.DataFrame(get_relevan_data(keywords))\n",
    "\n",
    "    #mendapatkan dataframe aggregate per issue\n",
    "    df_issue = get_df_issue(df)\n",
    "\n",
    "    #chunk df_issue\n",
    "    data_chunk = chunk_dataframe(df_issue, 100)\n",
    "\n",
    "    #mendapatkan central issue berdasarkan viral score tertinggi\n",
    "    df_central = get_central_issue(data_chunk[0])\n",
    "\n",
    "    LIST_UNIFIED_ISSUE = df_central['unified_issue'].to_list()\n",
    "\n",
    "    SISA = data_chunk[0][~data_chunk[0]['index'].isin([j for i in df_central['list_issue_id'] for j in i])]\n",
    "    if not SISA.empty:\n",
    "        data_chunk[1] = pd.concat([data_chunk[1], SISA])\n",
    "\n",
    "\n",
    "\n",
    "    #mendapatkan seluruh unified issue \n",
    "    all_result = []\n",
    "    for DC in tqdm(data_chunk[1:]):\n",
    "        issue_list = []\n",
    "        for idx, row in DC.iterrows():\n",
    "            issue_list.append({\"id\": row['index'], \"issue\": row['issue']})\n",
    "\n",
    "\n",
    "        df_predict = ''\n",
    "\n",
    "        while True:\n",
    "            if type(df_predict)!=str:\n",
    "                issue_list = [i for i in issue_list if i['id'] not in [j for i in df_predict['list_issue_id'] for j in i]]\n",
    "            # Buat prompt yang lebih terstruktur dan eksplisit\n",
    "            prompt = f\"\"\"\n",
    "                Kamu adalah Media Social Analyst Expert dengan keahlian dalam pengelompokan tematik dan kategorisasi konten sosial media.\n",
    "\n",
    "                # TUGAS UTAMA\n",
    "                Analisis dan kelompokkan list issue baru ke dalam kelompok tematik yang sudah ada (jika relevan) atau buat kelompok baru jika diperlukan.\n",
    "\n",
    "                # ATURAN PENGELOMPOKAN\n",
    "                1. PENTING: Prioritaskan pengelompokan ke dalam kategori yang sudah ada jika terdapat kemiripan tema.\n",
    "                2. Buat kategori baru HANYA jika issue tidak cocok dengan kelompok yang sudah ada.\n",
    "                3. Setiap issue ID HANYA boleh masuk ke SATU kelompok (mutually exclusive).\n",
    "                4. Hindari TUMPANG TINDIH issue di antara kelompok-kelompok.\n",
    "\n",
    "                # KELOMPOK YANG SUDAH ADA\n",
    "                Berikut adalah kelompok tematik yang sudah ada dan HARUS digunakan jika relevan:\n",
    "                ```\n",
    "                {LIST_UNIFIED_ISSUE}\n",
    "                ```\n",
    "\n",
    "                # LIST ISSUE YANG AKAN DIKELOMPOKKAN\n",
    "                ```\n",
    "                {issue_list}\n",
    "                ```\n",
    "\n",
    "                # PETUNJUK PENGELOMPOKAN\n",
    "                - Jika issue memiliki kemiripan SUBSTANSIAL dengan kelompok yang sudah ada → masukkan ke kelompok tersebut\n",
    "                - Jika issue SAMA SEKALI TIDAK TERKAIT dengan kelompok yang ada → buat kelompok baru\n",
    "                - Kemiripan didasarkan pada tema, topik, kata kunci, dan konteks (bukan sentimen)\n",
    "                - Usahakan untuk TIDAK membuat kelompok baru jika masih bisa dimasukkan ke kelompok yang sudah ada\n",
    "\n",
    "                # FORMAT OUTPUT (JSON)\n",
    "                [\n",
    "                  {{\n",
    "                    \"unified_issue\": \"Nama Issue Kelompok (gunakan dari list yang sudah ada atau buat baru)\",\n",
    "                    \"description\": \"Deskripsi singkat dan jelas tentang tema kelompok ini\",\n",
    "                    \"list_issue_id\": [1, 5, 10, 15] // Daftar ID issue yang masuk dalam kelompok ini\n",
    "                  }},\n",
    "                  ...\n",
    "                ]\n",
    "\n",
    "                # KRITERIA KUALITAS\n",
    "                - Setiap kelompok sebaiknya memiliki minimal 2 issue\n",
    "                - Nama kelompok baru harus singkat, jelas, dan deskriptif\n",
    "                - Prioritaskan penggunaan nama kelompok yang sudah ada\n",
    "                - Pastikan seluruh index issue masuk ke setiap kelompok tanpa tersisia\n",
    "\n",
    "                PENTING: Hasilkan HANYA format JSON murni tanpa komentar, penjelasan, atau notasi lain.\"\"\"\n",
    "\n",
    "            predict = call_gemini(prompt)\n",
    "            df_predict = pd.DataFrame(eval(re.findall(r'\\[.*\\]',predict, flags=re.I|re.S)[0]))\n",
    "            all_result.append(df_predict)\n",
    "\n",
    "            LIST_UNIFIED_ISSUE.extend(df_predict['unified_issue'].to_list())\n",
    "\n",
    "            LIST_UNIFIED_ISSUE = list(set(LIST_UNIFIED_ISSUE))\n",
    "\n",
    "\n",
    "            SISA = set([i['id'] for i in issue_list])- set([j for i in df_predict['list_issue_id'] for j in i])\n",
    "\n",
    "            if not SISA:\n",
    "                break\n",
    "\n",
    "    all_result.append(df_central)\n",
    "    topics = pd.concat(all_result)\n",
    "\n",
    "    #merge dengan nama issue berdasarkan id\n",
    "    all_topics = topics.groupby('unified_issue').agg({'list_issue_id':[lambda s: [j for i in s for j in i], lambda s: len([j for i in s for j in i])]}).reset_index()\n",
    "    all_topics.columns = ['unified_issue','list_issue','total_issue']\n",
    "\n",
    "    merge_all_topics = []\n",
    "    for _,i in all_topics.iterrows():\n",
    "        data = df_issue[df_issue['index'].isin(i['list_issue'])]\n",
    "        dt = data[['total_posts','viral_score','reach_score','negative','positive','neutral']].sum().to_dict()\n",
    "        dt.update({'unified_issue':i['unified_issue'], 'list_issue':data['issue'].to_list()})\n",
    "\n",
    "        merge_all_topics.append(dt)\n",
    "\n",
    "    df_all_topics = pd.DataFrame(merge_all_topics).sort_values('viral_score', ascending = False)\n",
    "\n",
    "\n",
    "\n",
    "    df_all_topics['share_of_voice'] = df_all_topics['total_posts']/df_all_topics['total_posts'].sum()*100\n",
    "\n",
    "\n",
    "    #ambil importance post sebagai perwakilan\n",
    "    list_data = []\n",
    "    for _,i in df_all_topics.iterrows():\n",
    "        unified_issue = i['unified_issue']\n",
    "        list_issue = i['list_issue']\n",
    "        list_caption = df[df['issue'].isin(list_issue)].sort_values('viral_score',ascending = False).drop_duplicates('post_caption')[:5]['post_caption'].to_list()\n",
    "\n",
    "        list_data.append({'unified_issue':unified_issue,\n",
    "                                'list_caption':list_caption,\n",
    "                          'sentiment negative':i['negative'],\n",
    "                          'sentiment positive':i['positive']})\n",
    "\n",
    "    list_prediction = []\n",
    "    for unified_issues_list in tqdm(chunk_list(list_data, 40)):\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Kamu adalah Media Social Analyst Expert dengan keahlian dalam analisis kategori dan isu-isu sosial media.\n",
    "\n",
    "        # TUGAS\n",
    "        Buatkan deskripsi yang informatif, akurat, dan komprehensif untuk setiap kategori unified_issue berikut ini.\n",
    "\n",
    "        # PETUNJUK\n",
    "        1. Deskripsi harus menjelaskan dengan jelas apa yang termasuk dalam kategori tersebut\n",
    "        2. Deskripsi harus ringkas namun komprehensif (maksimal 2-3 kalimat)\n",
    "        3. Gunakan bahasa yang netral dan profesional\n",
    "        4. Fokus pada konten dan cakupan dari kategori isu tersebut\n",
    "        5. Jangan menyertakan opini pribadi atau bias dalam deskripsi\n",
    "        6. Berikan juga description berdasarkan sentimentnya\n",
    "\n",
    "        # DATA UNIFIED_ISSUE\n",
    "        ```\n",
    "        {unified_issues_list}\n",
    "        ```\n",
    "\n",
    "        # FORMAT OUTPUT\n",
    "        Berikan hasil dalam format JSON seperti berikut:\n",
    "        ```\n",
    "        [\n",
    "          {{\n",
    "            \"unified_issue\": \"Nama Unified Issue\",\n",
    "            \"description\": \"Deskripsi komprehensif tentang unified issue ini\"\n",
    "          }},\n",
    "          {{\n",
    "            \"unified_issue\": \"Nama Unified Issue Lainnya\",\n",
    "            \"description\": \"Deskripsi komprehensif tentang unified issue ini\"\n",
    "          }},\n",
    "          ...\n",
    "        ]\n",
    "        ```\n",
    "\n",
    "        ### HARD RULE\n",
    "        - Berikan HANYA output JSON tanpa penjelasan atau komentar tambahan.\n",
    "        - Hindari penjelasan \"This category focuses\" , contoh description yang baik seperti ini \"Conversations praised recent innovations in the nickel industry that emphasize sustainability and local economic growth, boosting positive sentiment towards Prabowo by 18%\"\n",
    "        \"\"\"\n",
    "        response_text = call_gemini(prompt)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            json_string = eval(re.findall(r'\\[.*\\]', response_text, flags = re.I|re.S)[0])\n",
    "        except:\n",
    "            response_text = (re.sub(f\"(?<!\\:\\s)\\\"([\\w\\s\\/\\.\\@\\-]+)\\\"(?![\\,\\:])\",r\"`\\1`\",response_text))\n",
    "            \n",
    "\n",
    "            try:\n",
    "                json_string = eval(re.findall(r'\\[.*\\]', response_text, flags = re.I|re.S)[0])\n",
    "            except:\n",
    "                json_string = []\n",
    "                for i in re.findall(r'{.*?}', response_text, flags=re.I|re.S):\n",
    "                    try:\n",
    "                        json_string.append(eval(i))\n",
    "                    except:\n",
    "                        pass  \n",
    "                    \n",
    "        \n",
    "        list_prediction.extend(json_string)\n",
    "\n",
    "\n",
    "    topics_result = pd.DataFrame(list_prediction).merge(df_all_topics, on = 'unified_issue')\n",
    "\n",
    "    return topics_result.sort_values('share_of_voice', ascending = False)\n",
    "\n",
    "def set_topics(keywords):\n",
    "\n",
    "    final_result = get_topics_overview(keywords)\n",
    "\n",
    "    result = ingest_to_elasticsearch(\n",
    "        data= [{'topics':final_result.to_dict(orient = 'records'),\n",
    "                'id':id_}],\n",
    "        hosts=\"http://localhost:9200\",\n",
    "        index=\"topics\",\n",
    "        id_field=\"id\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f272b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:26:36.204423Z",
     "start_time": "2025-04-17T15:26:36.198876Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "def create_uuid(keyword):\n",
    "    # Gunakan namespace standar (ada juga untuk URL, DNS, dll)\n",
    "    namespace = uuid.NAMESPACE_DNS\n",
    "\n",
    "    return uuid.uuid5(namespace, keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d5f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T15:40:58.416660Z",
     "start_time": "2025-04-17T15:27:16.158942Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mysql=About_MySQL( db_host, db_port, db_user, db_password, db_name)\n",
    "\n",
    "query = \"select * from keyword_projects\"\n",
    "data_projects = mysql.to_pull_data(query)\n",
    "\n",
    "for _ , i in data_projects.groupby(['project_name','owner_id']).agg({'relevan_keyword':list}).reset_index().iterrows():\n",
    "    id_ = create_uuid(\"{}_{}\".format(i['owner_id'], i['project_name']))\n",
    "    print(\"{}_{}\".format(i['owner_id'], i['project_name']))\n",
    "    keywords = i['relevan_keyword']\n",
    "    set_topics(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccd35b",
   "metadata": {},
   "source": [
    "## search topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841743f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:24:03.056500Z",
     "start_time": "2025-04-18T06:24:03.034567Z"
    },
    "code_folding": [
     3
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((((((((((((((((((((( MASUK ))))))))))))))))))))))\n",
      "Successfully connected to http://localhost:9200\n"
     ]
    }
   ],
   "source": [
    "from utils.topics_overview import search_topics\n",
    "#INPUT\n",
    "owner_id = 5\n",
    "project_name = 'gibran rakas'\n",
    "keywords = [\n",
    "            \"pdip\",\n",
    "            \"gerindra\",\n",
    "            \"solo\",\n",
    "            \"wakil presiden terpilih\",\n",
    "            \"wali kota solo\",\n",
    "            \"gibran raka\",\n",
    "            \"pilpres 2024\",\n",
    "            \"kaesang pangarep\",\n",
    "            \"anak presiden jokowi\",\n",
    "            \"prabowo gibran\"\n",
    "          ]\n",
    "\n",
    "hasil = search_topics(  \n",
    "    owner_id = owner_id,\n",
    "    project_name = project_name,\n",
    "    es_host=None,\n",
    "    keywords=keywords,\n",
    "    sentiment = ['neutral'],\n",
    "    channels = ['twitter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a9db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:46:05.470451Z",
     "start_time": "2025-04-18T02:46:05.433574Z"
    },
    "code_folding": [
     13,
     48,
     104
    ]
   },
   "outputs": [],
   "source": [
    "from utils.es_client import get_elasticsearch_client\n",
    "from utils.list_of_mentions import get_mentions\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import uuid\n",
    "from typing import List, Dict, Union, Any, Optional\n",
    "\n",
    "def create_uuid(keyword):\n",
    "    # Gunakan namespace standar (ada juga untuk URL, DNS, dll)\n",
    "    namespace = uuid.NAMESPACE_DNS\n",
    "\n",
    "    return uuid.uuid5(namespace, keyword)\n",
    "\n",
    "def matching_issue(final_result, df_data):\n",
    "    #final_result : dataframe yg isinya group topics \n",
    "    #df_data :dataframe yang ingin di cari grup nya\n",
    "     \n",
    "    hasil = []\n",
    "    for _,i  in final_result.iterrows():\n",
    "        list_issue = i['list_issue']\n",
    "        dt = df_data[df_data['issue'].isin(list_issue)]\n",
    "\n",
    "\n",
    "        if dt.empty:\n",
    "            continue\n",
    "\n",
    "        row = i.to_dict().copy()\n",
    "\n",
    "        agg_sentiment = dt.groupby('sentiment').size().to_dict()\n",
    "        sentiment_categories = ['positive', 'negative', 'neutral']\n",
    "        for category in sentiment_categories:\n",
    "            agg_sentiment.setdefault(category, 0)\n",
    "\n",
    "        agg_sentiment = {key: value for key, value in agg_sentiment.items() if key in sentiment_categories}\n",
    "\n",
    "\n",
    "        agg_score = dt[['viral_score','reach_score']].sum().to_dict()\n",
    "\n",
    "        row.update(agg_sentiment)\n",
    "        row.update(agg_score)\n",
    "        row.update({'total_posts':dt.shape[0]})\n",
    "        hasil.append(row)\n",
    "\n",
    "    df = pd.DataFrame(hasil).fillna(0)\n",
    "    df['share_of_voice'] = df['total_posts']/df['total_posts'].sum()*100\n",
    "\n",
    "    return df.to_dict(orient = 'records')\n",
    "\n",
    "def search_topics(  \n",
    "    owner_id = None,\n",
    "    project_name = None,\n",
    "    es_host=None,\n",
    "    es_username=None,\n",
    "    es_password=None,\n",
    "    use_ssl=False,\n",
    "    verify_certs=False,\n",
    "    ca_certs=None,\n",
    "    keywords=None,\n",
    "    search_exact_phrases=False,\n",
    "    case_sensitive=False,\n",
    "    sentiment=None,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    date_filter=\"last 30 days\",\n",
    "    custom_start_date=None,\n",
    "    custom_end_date=None,\n",
    "    channels=None,\n",
    "    importance=\"all mentions\",\n",
    "    influence_score_min=None,\n",
    "    influence_score_max=None,\n",
    "    region=None,\n",
    "    language=None,\n",
    "    domain=None):\n",
    "    \n",
    "    print('(((((((((((((((((((((( MASUK ))))))))))))))))))))))')\n",
    "    es = get_elasticsearch_client(\n",
    "        es_host=es_host,\n",
    "        es_username=es_username,\n",
    "        es_password=es_password,\n",
    "        use_ssl=use_ssl,\n",
    "        verify_certs=verify_certs,\n",
    "        ca_certs=ca_certs\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #PROCESS\n",
    "    id_ = create_uuid(\"{}_{}\".format(owner_id, project_name))\n",
    "\n",
    "    query = {\n",
    "        \"source\":[],\n",
    "      \"query\": {\n",
    "        \"match\": {\n",
    "          \"_id\": id_\n",
    "        }\n",
    "      }\n",
    "\n",
    "    }\n",
    "\n",
    "    response = es.search(\n",
    "        index='topics',\n",
    "        body=query\n",
    "    )\n",
    "\n",
    "    data_project = [hit[\"_source\"] for hit in response[\"hits\"][\"hits\"]]\n",
    "    if data_project:\n",
    "\n",
    "        #project sudah tergenerate\n",
    "        final_result = pd.DataFrame(data_project[0]['topics'])\n",
    "\n",
    "        #pake filter berdasarkan input user\n",
    "        result = get_mentions(\n",
    "            source= [\"issue\", \"reach_score\", \"viral_score\", \"sentiment\", \"link_post\"],\n",
    "            page_size=10000,\n",
    "            es_host=es_host,    \n",
    "            es_username=es_username,\n",
    "            es_password=es_password,\n",
    "            use_ssl=use_ssl,\n",
    "            verify_certs=verify_certs,\n",
    "            ca_certs=ca_certs,\n",
    "            keywords=keywords,\n",
    "            search_exact_phrases=search_exact_phrases,\n",
    "            case_sensitive=case_sensitive,\n",
    "            sentiment=sentiment,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            date_filter=date_filter,\n",
    "            custom_start_date=custom_start_date,\n",
    "            custom_end_date=custom_end_date,\n",
    "            channels=channels,\n",
    "            importance=importance,\n",
    "            influence_score_min=influence_score_min,\n",
    "            influence_score_max=influence_score_max,\n",
    "            region=region,\n",
    "            language=language,\n",
    "            domain=domain,\n",
    "            sort_type = 'popular'\n",
    "    \n",
    "        )\n",
    "\n",
    "        df_data = pd.DataFrame(result['data'])\n",
    "        \n",
    "        if df_data.empty:\n",
    "            return []\n",
    "        \n",
    "        return matching_issue(final_result, df_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f0ab6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T02:46:06.298402Z",
     "start_time": "2025-04-18T02:46:06.133593Z"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "\"es_host\":\"localhost:9200\",\n",
    "  \"keywords\": [\n",
    "    \"gibran\"\n",
    "  ],\n",
    "  \"owner_id\": \"5\",\n",
    "  \"project_name\": \"gibran raka\"\n",
    "}\n",
    "\n",
    "hasil = search_topics(  \n",
    "    owner_id = '5',\n",
    "    project_name = \"gibran raka\",\n",
    "    es_host=None,\n",
    "    keywords=[\"gibran\"],\n",
    "    channels = ['reddit'])\n",
    "pd.DataFrame(hasil).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d2d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:24:21.874560Z",
     "start_time": "2025-04-18T06:24:19.039861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((((((((((((((((((((( MASUK ))))))))))))))))))))))\n",
      "Successfully connected to http://localhost:9200\n",
      "Successfully connected to http://localhost:9200\n"
     ]
    }
   ],
   "source": [
    "from utils.topics_overview import search_topics\n",
    "\n",
    "hasil = search_topics(  \n",
    "    owner_id = '5',\n",
    "    project_name = \"gibran raka\",\n",
    "    es_host=None,\n",
    "    keywords=[\"prabowo\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc9d3639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:24:24.532917Z",
     "start_time": "2025-04-18T06:24:24.481488Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unified_issue</th>\n",
       "      <th>description</th>\n",
       "      <th>total_posts</th>\n",
       "      <th>viral_score</th>\n",
       "      <th>reach_score</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>list_issue</th>\n",
       "      <th>share_of_voice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Government Policies and Programs</td>\n",
       "      <td>This category focuses on social media conversa...</td>\n",
       "      <td>113</td>\n",
       "      <td>53.568278</td>\n",
       "      <td>257.200000</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>59</td>\n",
       "      <td>[Focus on safety, not just profit, Pertamax co...</td>\n",
       "      <td>5.972516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lebaran and Return Traffic</td>\n",
       "      <td>This category examines social media conversati...</td>\n",
       "      <td>43</td>\n",
       "      <td>21.476498</td>\n",
       "      <td>69.350000</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>[Bank DKI ATM interbank transactions restored,...</td>\n",
       "      <td>2.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prabowo Subianto's Activities</td>\n",
       "      <td>This category analyzes social media conversati...</td>\n",
       "      <td>246</td>\n",
       "      <td>24.024425</td>\n",
       "      <td>512.695556</td>\n",
       "      <td>53</td>\n",
       "      <td>65</td>\n",
       "      <td>128</td>\n",
       "      <td>[Najwa Shihab interviews Prabowo Subianto, Pra...</td>\n",
       "      <td>13.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prabowo-Megawati Meeting</td>\n",
       "      <td>This category analyzes social media discussion...</td>\n",
       "      <td>205</td>\n",
       "      <td>112.655452</td>\n",
       "      <td>356.220000</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>146</td>\n",
       "      <td>[Megawati and Prabowo meeting to discuss natio...</td>\n",
       "      <td>10.835095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transportation and Infrastructure</td>\n",
       "      <td>This category analyzes social media conversati...</td>\n",
       "      <td>17</td>\n",
       "      <td>5.004765</td>\n",
       "      <td>27.150000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[Traffic engineering due to increased flow, 59...</td>\n",
       "      <td>0.898520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>New Issue: Jokowi's Solo Residence Visited</td>\n",
       "      <td>This category focuses on the social media disc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Jokowi's Solo residence visited by thousands]</td>\n",
       "      <td>0.052854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Environmental Sustainability</td>\n",
       "      <td>This category explores discussions about envir...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Fitri individuals bring goodness to environment]</td>\n",
       "      <td>0.052854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Erosion of Democracy</td>\n",
       "      <td>This category examines the social media discus...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201258</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Erosion of democracy in Indonesia]</td>\n",
       "      <td>0.052854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Defense Industry</td>\n",
       "      <td>This category examines the social media discus...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[DEFEND ID praised for defense industry]</td>\n",
       "      <td>0.052854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Youngest Regional Heads in Indonesia 2025-2030</td>\n",
       "      <td>This category profiles the youngest regional h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Youngest regional heads in Indonesia 2025-2030]</td>\n",
       "      <td>0.052854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      unified_issue  \\\n",
       "0                  Government Policies and Programs   \n",
       "1                        Lebaran and Return Traffic   \n",
       "2                     Prabowo Subianto's Activities   \n",
       "3                          Prabowo-Megawati Meeting   \n",
       "4                 Transportation and Infrastructure   \n",
       "..                                              ...   \n",
       "145      New Issue: Jokowi's Solo Residence Visited   \n",
       "146                    Environmental Sustainability   \n",
       "147                            Erosion of Democracy   \n",
       "148                                Defense Industry   \n",
       "149  Youngest Regional Heads in Indonesia 2025-2030   \n",
       "\n",
       "                                           description  total_posts  \\\n",
       "0    This category focuses on social media conversa...          113   \n",
       "1    This category examines social media conversati...           43   \n",
       "2    This category analyzes social media conversati...          246   \n",
       "3    This category analyzes social media discussion...          205   \n",
       "4    This category analyzes social media conversati...           17   \n",
       "..                                                 ...          ...   \n",
       "145  This category focuses on the social media disc...            1   \n",
       "146  This category explores discussions about envir...            1   \n",
       "147  This category examines the social media discus...            1   \n",
       "148  This category examines the social media discus...            1   \n",
       "149  This category profiles the youngest regional h...            1   \n",
       "\n",
       "     viral_score  reach_score  negative  positive  neutral  \\\n",
       "0      53.568278   257.200000        24        30       59   \n",
       "1      21.476498    69.350000         0        17       26   \n",
       "2      24.024425   512.695556        53        65      128   \n",
       "3     112.655452   356.220000         4        55      146   \n",
       "4       5.004765    27.150000         4         4        9   \n",
       "..           ...          ...       ...       ...      ...   \n",
       "145     0.325581     2.300000         0         1        0   \n",
       "146     0.296296     1.400000         0         1        0   \n",
       "147     0.201258     8.300000         1         0        0   \n",
       "148     0.217391     2.350000         0         1        0   \n",
       "149     0.000000     6.600000         0         0        1   \n",
       "\n",
       "                                            list_issue  share_of_voice  \n",
       "0    [Focus on safety, not just profit, Pertamax co...        5.972516  \n",
       "1    [Bank DKI ATM interbank transactions restored,...        2.272727  \n",
       "2    [Najwa Shihab interviews Prabowo Subianto, Pra...       13.002114  \n",
       "3    [Megawati and Prabowo meeting to discuss natio...       10.835095  \n",
       "4    [Traffic engineering due to increased flow, 59...        0.898520  \n",
       "..                                                 ...             ...  \n",
       "145     [Jokowi's Solo residence visited by thousands]        0.052854  \n",
       "146  [Fitri individuals bring goodness to environment]        0.052854  \n",
       "147                [Erosion of democracy in Indonesia]        0.052854  \n",
       "148           [DEFEND ID praised for defense industry]        0.052854  \n",
       "149   [Youngest regional heads in Indonesia 2025-2030]        0.052854  \n",
       "\n",
       "[150 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(hasil).fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c1d11",
   "metadata": {},
   "source": [
    "## if topics belum ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f652a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:12:21.568180Z",
     "start_time": "2025-04-18T06:11:57.022404Z"
    },
    "code_folding": [
     26
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V2\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from utils.gemini import call_gemini\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Union, Any, Optional\n",
    "\n",
    "\n",
    "\n",
    "#!pip install mysql-connector-python\n",
    "db_host = \"34.101.146.213\"\n",
    "db_port = 3306\n",
    "db_user = \"arilindra21\"\n",
    "db_password = \"sukabumi030495\"\n",
    "db_name = \"auth_api_db\"\n",
    "       \n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "class About_MySQL:\n",
    "    def __init__(self, db_host, db_port, db_user, db_password, db_name):\n",
    "        # Membuat URL koneksi dengan format SQLAlchemy\n",
    "        self.database_url = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "        \n",
    "        # Membuat engine SQLAlchemy\n",
    "        self.engine = create_engine(self.database_url)\n",
    "\n",
    "    def to_pull_data(self, query):\n",
    "        # Mengambil data menggunakan query yang diberikan dan mengonversinya ke DataFrame\n",
    "        with self.engine.connect() as connection:\n",
    "            # Menjalankan query dan mengonversi hasilnya ke DataFrame\n",
    "            df = pd.read_sql(text(query), connection)\n",
    "        return df\n",
    "    \n",
    "    def to_push_data(self, dataframe: pd.DataFrame, table_name: str, if_exist: str = 'replace'):\n",
    "        \"\"\"\n",
    "        Menyimpan DataFrame ke tabel MySQL.\n",
    "        \n",
    "        Parameters:\n",
    "        - dataframe: pd.DataFrame yang akan disimpan\n",
    "        - table_name: nama tabel tujuan\n",
    "        - if_exist: 'replace' untuk mengganti tabel, 'append' untuk menambahkan data\n",
    "        \"\"\"\n",
    "        assert if_exist in ['replace', 'append'], \"Parameter 'if_exist' harus 'replace' atau 'append'\"\n",
    "        \n",
    "        dataframe.to_sql(\n",
    "            name=table_name,\n",
    "            con=self.engine,\n",
    "            if_exists=if_exist,\n",
    "            index=False,\n",
    "            method='multi'\n",
    "        )\n",
    "        print(f\"✅ Data berhasil dipush ke tabel `{table_name}` dengan mode `{if_exist}`.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67a82105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:18:04.950071Z",
     "start_time": "2025-04-18T06:18:04.591225Z"
    },
    "code_folding": [
     1,
     50,
     64,
     79,
     170,
     204,
     256,
     455,
     459
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def ingest_to_elasticsearch(data: Union[Dict[str, Any], List[Dict[str, Any]]],\n",
    "                           hosts: Union[str, List[str]] = 'http://localhost:9200',\n",
    "                           index: str = 'my_index',\n",
    "                           bulk_size: int = 1000,\n",
    "                           id_field: Optional[str] = None,\n",
    "                           **es_kwargs) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ingest data into Elasticsearch using the official Elasticsearch Python client\n",
    "    \n",
    "    Args:\n",
    "        data: Single document (dict) or list of documents to ingest\n",
    "        hosts: Elasticsearch host URL or list of hosts\n",
    "        index: Name of the index\n",
    "        bulk_size: Number of documents to send in each bulk request\n",
    "        id_field: Field to use as document ID\n",
    "        es_kwargs: Additional keyword arguments for Elasticsearch client\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with statistics about the bulk operation\n",
    "    \"\"\"\n",
    "    # Initialize Elasticsearch client\n",
    "    es = Elasticsearch(hosts=hosts, **es_kwargs)\n",
    "    \n",
    "    # Convert single document to list if needed\n",
    "    documents = data if isinstance(data, list) else [data]\n",
    "    \n",
    "    # Prepare documents for bulk operation\n",
    "    actions = []\n",
    "    for doc in documents:\n",
    "        action = {\n",
    "            \"_index\": index,\n",
    "            \"_source\": doc\n",
    "        }\n",
    "        \n",
    "        # Add document ID if provided\n",
    "        if id_field and id_field in doc:\n",
    "            action[\"_id\"] = doc[id_field]\n",
    "            \n",
    "        actions.append(action)\n",
    "    \n",
    "    # Execute bulk operation\n",
    "    result = helpers.bulk(es, actions, chunk_size=bulk_size)\n",
    "    \n",
    "    return {\n",
    "        \"success_count\": result[0],\n",
    "        \"error_count\": result[1],\n",
    "        \"total_documents\": len(documents)\n",
    "    }\n",
    "\n",
    "def chunk_list(data: List, chunk_size: int) -> List[List]:\n",
    "    \"\"\"\n",
    "    Membagi list menjadi beberapa chunk berdasarkan ukuran yang diberikan.\n",
    "\n",
    "    Parameters:\n",
    "    - data: List yang akan dibagi\n",
    "    - chunk_size: Ukuran setiap chunk\n",
    "\n",
    "    Returns:\n",
    "    - List yang berisi chunk-chunk dari list\n",
    "    \"\"\"\n",
    "    # Membagi list data menjadi chunk sesuai dengan ukuran chunk_size\n",
    "    return [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "\n",
    "def chunk_dataframe(df: pd.DataFrame, chunk_size: int) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Membagi DataFrame menjadi beberapa chunk berdasarkan ukuran yang diberikan.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame yang akan dibagi\n",
    "    - chunk_size: Ukuran setiap chunk (baris)\n",
    "\n",
    "    Returns:\n",
    "    - List yang berisi DataFrame chunked\n",
    "    \"\"\"\n",
    "    # Menghitung jumlah chunk yang dibutuhkan\n",
    "    chunked_data = [df.iloc[i:i + chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "    return chunked_data\n",
    "\n",
    "class ElasticsearchHelper:\n",
    "    def __init__(self, host: str):\n",
    "        self.host = host\n",
    "        self.es = self.connect()\n",
    "\n",
    "    def connect(self) -> Elasticsearch:\n",
    "        \"\"\"Membuat koneksi ke Elasticsearch.\"\"\"\n",
    "        try:\n",
    "            es = Elasticsearch(\n",
    "                self.host,\n",
    "                verify_certs=False  # Hanya untuk development, non-TLS\n",
    "            )\n",
    "            return es\n",
    "        except ElasticsearchException as e:\n",
    "            print(f\"Failed to connect to Elasticsearch: {e}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_data(self, index: str, query: dict, size: int = 1000) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Tarik data dari Elasticsearch dengan scan helpers untuk data besar\"\"\"\n",
    "        try:\n",
    "            if not self.es:\n",
    "                raise ConnectionError(\"Tidak dapat terkoneksi dengan Elasticsearch.\")\n",
    "            \n",
    "            # Gunakan helpers.scan untuk menarik data besar\n",
    "            scan_response = helpers.scan(\n",
    "                client=self.es,\n",
    "                index=index,\n",
    "                query=query,\n",
    "                size=size,\n",
    "                scroll=\"2m\"  # Menggunakan scroll selama 2 menit untuk mengambil data\n",
    "            )\n",
    "\n",
    "            # Ambil hasil dari scan\n",
    "            all_hits = [doc[\"_source\"] for doc in scan_response]\n",
    "\n",
    "            return all_hits\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error umum: {e}\")\n",
    "            return []\n",
    "        \n",
    "def get_relevan_data(keywords,start_date=None, sampling = False ):\n",
    "    \n",
    "    \n",
    "    current_date = datetime.now()\n",
    "    if not start_date:\n",
    "        # Hitung tanggal 120 hari ke belakang dari sekarang\n",
    "        \n",
    "        date_120_days_ago = current_date - timedelta(days=120)\n",
    "        # Format tanggal ke format ISO 8601 yang kompatibel dengan Elasticsearch\n",
    "        start_date = date_120_days_ago.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    es_helper = ElasticsearchHelper(host=\"http://localhost:9200\")\n",
    "    query = {\n",
    "        \"_source\": [\"issue\", \"post_caption\", \"reach_score\", \"viral_score\", \"sentiment\", \"link_post\", \"channel\"],\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"post_caption\": {\n",
    "                                \"query\": keyword,\n",
    "                                \"operator\": \"and\"  # Semua kata dalam keyword harus ada\n",
    "                            }\n",
    "                        }\n",
    "                    } for keyword in keywords\n",
    "                ],\n",
    "              \"must\": [\n",
    "                            {\n",
    "                                \"range\": {\n",
    "                                    \"post_created_at\": {\n",
    "                                        \"gte\": start_date,  # Greater than or equal to 120 hari yang lalu\n",
    "                                        \"lte\": current_date.strftime(\"%Y-%m-%d %H:%M:%S\")  # Less than or equal to sekarang\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                \"must_not\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"issue\": \"Not Specified\"  # Filter: 'issue' tidak boleh \"Not Specified\"\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"minimum_should_match\": 1  # Minimal satu keyword yang cocok\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return es_helper.fetch_data(index=\"twitter_data,linkedin_data,news_data,reddit_data,youtube_data\",\n",
    "                                query=query, size=10000)\n",
    "    \n",
    "def get_df_issue(df):\n",
    "    issue_total_posts = df.groupby('issue').size().reset_index(name='total_posts')\n",
    "\n",
    "    # Hitung sum viral_score dan reach_score per issue\n",
    "    issue_scores = df.groupby('issue').agg({\n",
    "        'viral_score': 'sum',\n",
    "        'reach_score': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Hitung total per jenis sentiment per issue\n",
    "    sentiment_counts = pd.crosstab(df['issue'], df['sentiment']).reset_index()\n",
    "\n",
    "    # 2. Gabungkan semua metrik\n",
    "    result = issue_total_posts.merge(issue_scores, on='issue')\n",
    "    result = result.merge(sentiment_counts, on='issue')\n",
    "\n",
    "    # 3. Buat fungsi untuk memastikan semua jenis sentiment ada (termasuk jika nilai 0)\n",
    "    def ensure_sentiment_columns(df, sentiments=['positive', 'negative', 'neutral']):\n",
    "        for sentiment in sentiments:\n",
    "            if sentiment not in df.columns:\n",
    "                df[sentiment] = 0\n",
    "        return df\n",
    "\n",
    "    result = ensure_sentiment_columns(result)\n",
    "\n",
    "    # 4. Sorting berdasarkan viral_score (optional, bisa diubah sesuai kebutuhan)\n",
    "    result = result.sort_values(by='viral_score', ascending=False)\n",
    "\n",
    "    # 5. Reset index\n",
    "    df_issue = result.reset_index(drop=True).reset_index()\n",
    "\n",
    "    # Tampilkan hasil\n",
    "    return df_issue\n",
    "\n",
    "def get_central_issue(data_chunk):\n",
    "    issue_list = []\n",
    "    for idx, row in data_chunk.iterrows():\n",
    "        issue_list.append({\"id\": row['index'], \"issue\": row['issue']})\n",
    "\n",
    "    # Buat prompt yang lebih terstruktur dan eksplisit\n",
    "    prompt = f\"\"\"\n",
    "    Kamu adalah Media Social Analyst Expert dengan keahlian khusus dalam pengelompokan tematik.\n",
    "\n",
    "    # TUGAS\n",
    "    Analisis dan kelompokkan list issue sosial media di bawah ini menjadi kelompok-kelompok tematik.\n",
    "\n",
    "    # INSTRUKSI PENTING\n",
    "    1. Setiap issue ID hanya boleh masuk ke dalam SATU kelompok (mutually exclusive).\n",
    "    2. Hindari tumpang tindih issue di antara kelompok-kelompok.\n",
    "    3. Fokus pada tema/topik utama dari setiap issue.\n",
    "    4. Buat nama kelompok yang singkat, jelas, dan mencerminkan tema utama.\n",
    "    5. Berikan deskripsi kelompok yang informatif dan komprehensif.\n",
    "\n",
    "    # LIST ISSUE\n",
    "    ```\n",
    "    {issue_list}\n",
    "    ```\n",
    "\n",
    "    # FORMAT OUTPUT\n",
    "    Kembalikan hasil pengelompokan dalam format JSON yang tepat berikut ini:\n",
    "    ```\n",
    "    [\n",
    "      {{\n",
    "        \"unified_issue\": \"Nama Issue Kelompok 1\",\n",
    "        \"description\": \"Deskripsi ringkas tentang tema kelompok ini\",\n",
    "        \"list_issue_id\": [1, 5, 10, 15] // Daftar ID yang masuk dalam kelompok ini\n",
    "      }},\n",
    "      {{\n",
    "        \"unified_issue\": \"Nama Issue Kelompok 2\",\n",
    "        \"description\": \"Deskripsi ringkas tentang tema kelompok ini\",\n",
    "        \"list_issue_id\": [2, 6, 11, 16] // Daftar ID yang masuk dalam kelompok ini\n",
    "      }},\n",
    "      ...\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    # PARAMETER KUALITAS\n",
    "    - Setiap kelompok sebaiknya memiliki minimal 2 issue\n",
    "    - Kelompokkan berdasarkan kemiripan tema/topik dan keywords, bukan sentimen\n",
    "\n",
    "    Berikan hasil pengelompokan dalam format JSON murni tanpa komentar atau penjelasan tambahan.\n",
    "    \"\"\"\n",
    "\n",
    "    centrality = call_gemini(prompt)\n",
    "    return pd.DataFrame(eval(re.findall(r'\\[.*\\]',centrality, flags=re.I|re.S)[0]))\n",
    "\n",
    "def get_topics_overview(keywords):\n",
    "    #mendapatkan raw data\n",
    "    df = pd.DataFrame(get_relevan_data(keywords))\n",
    "\n",
    "    #mendapatkan dataframe aggregate per issue\n",
    "    df_issue = get_df_issue(df)\n",
    "\n",
    "    #chunk df_issue\n",
    "    data_chunk = chunk_dataframe(df_issue, 100)\n",
    "\n",
    "    #mendapatkan central issue berdasarkan viral score tertinggi\n",
    "    df_central = get_central_issue(data_chunk[0])\n",
    "\n",
    "    LIST_UNIFIED_ISSUE = df_central['unified_issue'].to_list()\n",
    "\n",
    "    SISA = data_chunk[0][~data_chunk[0]['index'].isin([j for i in df_central['list_issue_id'] for j in i])]\n",
    "    if not SISA.empty:\n",
    "        data_chunk[1] = pd.concat([data_chunk[1], SISA])\n",
    "\n",
    "\n",
    "\n",
    "    #mendapatkan seluruh unified issue \n",
    "    all_result = []\n",
    "    for DC in tqdm(data_chunk[1:]):\n",
    "        issue_list = []\n",
    "        for idx, row in DC.iterrows():\n",
    "            issue_list.append({\"id\": row['index'], \"issue\": row['issue']})\n",
    "\n",
    "\n",
    "        df_predict = ''\n",
    "\n",
    "        while True:\n",
    "            if type(df_predict)!=str:\n",
    "                issue_list = [i for i in issue_list if i['id'] not in [j for i in df_predict['list_issue_id'] for j in i]]\n",
    "            # Buat prompt yang lebih terstruktur dan eksplisit\n",
    "            prompt = f\"\"\"\n",
    "                Kamu adalah Media Social Analyst Expert dengan keahlian dalam pengelompokan tematik dan kategorisasi konten sosial media.\n",
    "\n",
    "                # TUGAS UTAMA\n",
    "                Analisis dan kelompokkan list issue baru ke dalam kelompok tematik yang sudah ada (jika relevan) atau buat kelompok baru jika diperlukan.\n",
    "\n",
    "                # ATURAN PENGELOMPOKAN\n",
    "                1. PENTING: Prioritaskan pengelompokan ke dalam kategori yang sudah ada jika terdapat kemiripan tema.\n",
    "                2. Buat kategori baru HANYA jika issue tidak cocok dengan kelompok yang sudah ada.\n",
    "                3. Setiap issue ID HANYA boleh masuk ke SATU kelompok (mutually exclusive).\n",
    "                4. Hindari TUMPANG TINDIH issue di antara kelompok-kelompok.\n",
    "\n",
    "                # KELOMPOK YANG SUDAH ADA\n",
    "                Berikut adalah kelompok tematik yang sudah ada dan HARUS digunakan jika relevan:\n",
    "                ```\n",
    "                {LIST_UNIFIED_ISSUE}\n",
    "                ```\n",
    "\n",
    "                # LIST ISSUE YANG AKAN DIKELOMPOKKAN\n",
    "                ```\n",
    "                {issue_list}\n",
    "                ```\n",
    "\n",
    "                # PETUNJUK PENGELOMPOKAN\n",
    "                - Jika issue memiliki kemiripan SUBSTANSIAL dengan kelompok yang sudah ada → masukkan ke kelompok tersebut\n",
    "                - Jika issue SAMA SEKALI TIDAK TERKAIT dengan kelompok yang ada → buat kelompok baru\n",
    "                - Kemiripan didasarkan pada tema, topik, kata kunci, dan konteks (bukan sentimen)\n",
    "                - Usahakan untuk TIDAK membuat kelompok baru jika masih bisa dimasukkan ke kelompok yang sudah ada\n",
    "\n",
    "                # FORMAT OUTPUT (JSON)\n",
    "                [\n",
    "                  {{\n",
    "                    \"unified_issue\": \"Nama Issue Kelompok (gunakan dari list yang sudah ada atau buat baru)\",\n",
    "                    \"description\": \"Deskripsi singkat dan jelas tentang tema kelompok ini\",\n",
    "                    \"list_issue_id\": [1, 5, 10, 15] // Daftar ID issue yang masuk dalam kelompok ini\n",
    "                  }},\n",
    "                  ...\n",
    "                ]\n",
    "\n",
    "                # KRITERIA KUALITAS\n",
    "                - Setiap kelompok sebaiknya memiliki minimal 2 issue\n",
    "                - Nama kelompok baru harus singkat, jelas, dan deskriptif\n",
    "                - Prioritaskan penggunaan nama kelompok yang sudah ada\n",
    "                - Pastikan seluruh index issue masuk ke setiap kelompok tanpa tersisia\n",
    "\n",
    "                PENTING: Hasilkan HANYA format JSON murni tanpa komentar, penjelasan, atau notasi lain.\"\"\"\n",
    "\n",
    "            predict = call_gemini(prompt)\n",
    "            df_predict = pd.DataFrame(eval(re.findall(r'\\[.*\\]',predict, flags=re.I|re.S)[0]))\n",
    "            all_result.append(df_predict)\n",
    "\n",
    "            LIST_UNIFIED_ISSUE.extend(df_predict['unified_issue'].to_list())\n",
    "\n",
    "            LIST_UNIFIED_ISSUE = list(set(LIST_UNIFIED_ISSUE))\n",
    "\n",
    "\n",
    "            SISA = set([i['id'] for i in issue_list])- set([j for i in df_predict['list_issue_id'] for j in i])\n",
    "\n",
    "            if not SISA:\n",
    "                break\n",
    "\n",
    "    all_result.append(df_central)\n",
    "    topics = pd.concat(all_result)\n",
    "\n",
    "    #merge dengan nama issue berdasarkan id\n",
    "    all_topics = topics.groupby('unified_issue').agg({'list_issue_id':[lambda s: [j for i in s for j in i], lambda s: len([j for i in s for j in i])]}).reset_index()\n",
    "    all_topics.columns = ['unified_issue','list_issue','total_issue']\n",
    "\n",
    "    merge_all_topics = []\n",
    "    for _,i in all_topics.iterrows():\n",
    "        data = df_issue[df_issue['index'].isin(i['list_issue'])]\n",
    "        dt = data[['total_posts','viral_score','reach_score','negative','positive','neutral']].sum().to_dict()\n",
    "        dt.update({'unified_issue':i['unified_issue'], 'list_issue':data['issue'].to_list()})\n",
    "\n",
    "        merge_all_topics.append(dt)\n",
    "\n",
    "    df_all_topics = pd.DataFrame(merge_all_topics).sort_values('viral_score', ascending = False)\n",
    "\n",
    "\n",
    "\n",
    "    df_all_topics['share_of_voice'] = df_all_topics['total_posts']/df_all_topics['total_posts'].sum()*100\n",
    "\n",
    "\n",
    "    #ambil importance post sebagai perwakilan\n",
    "    list_data = []\n",
    "    for _,i in df_all_topics.iterrows():\n",
    "        unified_issue = i['unified_issue']\n",
    "        list_issue = i['list_issue']\n",
    "        list_caption = df[df['issue'].isin(list_issue)].sort_values('viral_score',ascending = False).drop_duplicates('post_caption')[:5]['post_caption'].to_list()\n",
    "\n",
    "        list_data.append({'unified_issue':unified_issue,\n",
    "                                'list_caption':list_caption,\n",
    "                          'sentiment negative':i['negative'],\n",
    "                          'sentiment positive':i['positive']})\n",
    "\n",
    "    list_prediction = []\n",
    "    for unified_issues_list in tqdm(chunk_list(list_data, 40)):\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Kamu adalah Media Social Analyst Expert dengan keahlian dalam analisis kategori dan isu-isu sosial media.\n",
    "\n",
    "        # TUGAS\n",
    "        Buatkan deskripsi yang informatif, akurat, dan komprehensif untuk setiap kategori unified_issue berikut ini.\n",
    "\n",
    "        # PETUNJUK\n",
    "        1. Deskripsi harus menjelaskan dengan jelas apa yang termasuk dalam kategori tersebut\n",
    "        2. Deskripsi harus ringkas namun komprehensif (maksimal 2-3 kalimat)\n",
    "        3. Gunakan bahasa yang netral dan profesional\n",
    "        4. Fokus pada konten dan cakupan dari kategori isu tersebut\n",
    "        5. Jangan menyertakan opini pribadi atau bias dalam deskripsi\n",
    "        6. Berikan juga description berdasarkan sentimentnya\n",
    "\n",
    "        # DATA UNIFIED_ISSUE\n",
    "        ```\n",
    "        {unified_issues_list}\n",
    "        ```\n",
    "\n",
    "        # FORMAT OUTPUT\n",
    "        Berikan hasil dalam format JSON seperti berikut:\n",
    "        ```\n",
    "        [\n",
    "          {{\n",
    "            \"unified_issue\": \"Nama Unified Issue\",\n",
    "            \"description\": \"Deskripsi komprehensif tentang unified issue ini\"\n",
    "          }},\n",
    "          {{\n",
    "            \"unified_issue\": \"Nama Unified Issue Lainnya\",\n",
    "            \"description\": \"Deskripsi komprehensif tentang unified issue ini\"\n",
    "          }},\n",
    "          ...\n",
    "        ]\n",
    "        ```\n",
    "\n",
    "        ### HARD RULE\n",
    "        - Berikan HANYA output JSON tanpa penjelasan atau komentar tambahan.\n",
    "        - Hindari penjelasan \"This category focuses\" , contoh description yang baik seperti ini \"Conversations praised recent innovations in the nickel industry that emphasize sustainability and local economic growth, boosting positive sentiment towards Prabowo by 18%\"\n",
    "        \"\"\"\n",
    "        response_text = call_gemini(prompt)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            json_string = eval(re.findall(r'\\[.*\\]', response_text, flags = re.I|re.S)[0])\n",
    "        except:\n",
    "            response_text = (re.sub(f\"(?<!\\:\\s)\\\"([\\w\\s\\/\\.\\@\\-]+)\\\"(?![\\,\\:])\",r\"`\\1`\",response_text))\n",
    "            \n",
    "\n",
    "            try:\n",
    "                json_string = eval(re.findall(r'\\[.*\\]', response_text, flags = re.I|re.S)[0])\n",
    "            except:\n",
    "                json_string = []\n",
    "                for i in re.findall(r'{.*?}', response_text, flags=re.I|re.S):\n",
    "                    try:\n",
    "                        json_string.append(eval(i))\n",
    "                    except:\n",
    "                        pass  \n",
    "                    \n",
    "        \n",
    "        list_prediction.extend(json_string)\n",
    "\n",
    "\n",
    "    topics_result = pd.DataFrame(list_prediction).merge(df_all_topics, on = 'unified_issue')\n",
    "\n",
    "    return topics_result.sort_values('share_of_voice', ascending = False)\n",
    "\n",
    "def set_topics(keywords):\n",
    "\n",
    "    final_result = get_topics_overview(keywords)\n",
    "\n",
    "    result = ingest_to_elasticsearch(\n",
    "        data= [{'topics':final_result.to_dict(orient = 'records'),\n",
    "                'id':id_}],\n",
    "        hosts=\"http://localhost:9200\",\n",
    "        index=\"topics\",\n",
    "        id_field=\"id\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6886b911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:21:18.630534Z",
     "start_time": "2025-04-18T06:18:24.309333Z"
    },
    "code_folding": [
     30,
     138
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:16<00:00,  7.59s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:31<00:00, 31.52s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unified_issue</th>\n",
       "      <th>description</th>\n",
       "      <th>sentiment_description</th>\n",
       "      <th>total_posts</th>\n",
       "      <th>viral_score</th>\n",
       "      <th>reach_score</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>list_issue</th>\n",
       "      <th>share_of_voice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prabowo's Domestic Policies</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a predominantly positiv...</td>\n",
       "      <td>214.0</td>\n",
       "      <td>110.649760</td>\n",
       "      <td>359.52</td>\n",
       "      <td>31.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>[Prabowo wants to remove import quotas, Prabow...</td>\n",
       "      <td>8.099924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Economic Issues and Policies</td>\n",
       "      <td>This category encompasses discussions and news...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>344.0</td>\n",
       "      <td>105.164758</td>\n",
       "      <td>789.46</td>\n",
       "      <td>86.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>[Subsidized housing for Gojek drivers, Qatar i...</td>\n",
       "      <td>13.020439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prabowo's Speeches and Statements</td>\n",
       "      <td>This category focuses on analyzing Prabowo's p...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>344.0</td>\n",
       "      <td>94.172025</td>\n",
       "      <td>867.21</td>\n",
       "      <td>55.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>[Prabowo's nervous speech in Turkish Parliamen...</td>\n",
       "      <td>13.020439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prabowo's International Relations</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>247.0</td>\n",
       "      <td>88.160128</td>\n",
       "      <td>435.64</td>\n",
       "      <td>38.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>[Prabowo voices support for Palestine in Turke...</td>\n",
       "      <td>9.348978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prabowo's Leadership and Performance</td>\n",
       "      <td>This category analyzes Prabowo's leadership st...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>146.0</td>\n",
       "      <td>84.120122</td>\n",
       "      <td>279.15</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>[Prabowo admits poor government communication,...</td>\n",
       "      <td>5.526117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gaza Conflict and Evacuation</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>62.977020</td>\n",
       "      <td>244.45</td>\n",
       "      <td>43.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>[Prabowo seeks support to evacuate Gazans, Pra...</td>\n",
       "      <td>5.753217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Indonesia-Turkey Relations</td>\n",
       "      <td>This category focuses on discussions and news ...</td>\n",
       "      <td>This category reflects a positive sentiment to...</td>\n",
       "      <td>193.0</td>\n",
       "      <td>59.592829</td>\n",
       "      <td>676.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>[Turkey and Indonesia strategic partnership ag...</td>\n",
       "      <td>7.305072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Public Opinion and Reactions</td>\n",
       "      <td>This category analyzes public opinion and reac...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>40.910934</td>\n",
       "      <td>326.80</td>\n",
       "      <td>36.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>[Support for Prabowo's import policy, Prabowo'...</td>\n",
       "      <td>4.504164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Political Dynamics and Coalitions</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a dynamic and evolving ...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>32.429507</td>\n",
       "      <td>220.68</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>[PDIP remains opposition after Mega-Prabowo me...</td>\n",
       "      <td>3.747161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business and Industry</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>25.279807</td>\n",
       "      <td>132.30</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[Rokhmin urges stronger, competitive food sect...</td>\n",
       "      <td>2.763058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lebaran and Security</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.006371</td>\n",
       "      <td>65.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Polri praised for managing Lebaran traffic, P...</td>\n",
       "      <td>1.476154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Titiek Puspa's Passing</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a somber and respectful...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.793880</td>\n",
       "      <td>96.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[Condolences for Titiek Puspa's passing, Prabo...</td>\n",
       "      <td>1.930356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trump's Tariffs and Impact</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>18.541262</td>\n",
       "      <td>252.40</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>[BPJS protects workers from Trump tariff impac...</td>\n",
       "      <td>4.125662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Education and Social Issues</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>17.465046</td>\n",
       "      <td>111.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[Kemensos prepares 'Sekolah Rakyat' for SMA, V...</td>\n",
       "      <td>2.043906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Civil Society and Advocacy</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a dynamic and evolving ...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.743148</td>\n",
       "      <td>91.10</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Peaceful protest faces multiple eviction atte...</td>\n",
       "      <td>1.476154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Legal and Regulatory Issues</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.321629</td>\n",
       "      <td>120.40</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[Meikarta developers urged to compensate consu...</td>\n",
       "      <td>1.514005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Corruption and Governance</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.930549</td>\n",
       "      <td>49.70</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[KPK supports impoverishing corruptors' famili...</td>\n",
       "      <td>0.984103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Indonesia's Food Security</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.644099</td>\n",
       "      <td>57.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Indonesia's food stocks strongest in 20 years...</td>\n",
       "      <td>1.249054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Transportation and Safety</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.373472</td>\n",
       "      <td>50.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Driving safety tips for long commutes, Invest...</td>\n",
       "      <td>0.984103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Koperasi Merah Putih</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.889393</td>\n",
       "      <td>73.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[ALFI supports logistics for Koperasi Merah Pu...</td>\n",
       "      <td>1.173354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Security and Defense</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.785933</td>\n",
       "      <td>53.85</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[Questioning TNI authority removal in narcotic...</td>\n",
       "      <td>1.021953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Presidential Transition and Leadership</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.089060</td>\n",
       "      <td>166.63</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>[Hasan Nasbi's evaluation depends on President...</td>\n",
       "      <td>1.854656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Regional Development</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.470689</td>\n",
       "      <td>74.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Papua Barat evaluates RPJMD supporting Prabow...</td>\n",
       "      <td>0.605602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Student Activism and Movement</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.356881</td>\n",
       "      <td>5.45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Civil resistance fragmented, student movement...</td>\n",
       "      <td>0.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Media and Communication</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a complex and evolving ...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.780878</td>\n",
       "      <td>62.29</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[Journalist assaulted during Kapolri coverage,...</td>\n",
       "      <td>0.681302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Family and Personal Relationships</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>47.40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Aufaa Luqman is Almas' brother, How to perfor...</td>\n",
       "      <td>0.189251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Housing and Infrastructure</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Subsidized housing for workers, first handove...</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hoaxes and Misinformation</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a concern about the spr...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Hoax lottery registration link Bank Sumut, Ho...</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Willie Salim's Charity</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Willie Salim cooks for 100k Bengkulu, Willie ...</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Indonesia U17 World Cup Qualification</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a highly positive senti...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.796353</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Indonesia U17 qualifies for World Cup, Indone...</td>\n",
       "      <td>0.189251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cultural Preservation</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a positive sentiment to...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.309369</td>\n",
       "      <td>21.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[HB II descendants preserve ancestral culture,...</td>\n",
       "      <td>0.302801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hajj and Religious Affairs</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a positive sentiment to...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.401450</td>\n",
       "      <td>12.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Kemenag Sumbar submits 5880 hajj visa documen...</td>\n",
       "      <td>0.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Natural Disasters and Impacts</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.303644</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Earthquake damages houses near Prabowo's resi...</td>\n",
       "      <td>0.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tourism and Hospitality</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.298246</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fave Hotel Banjarmasin holds kids fashion, Fa...</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ministerial Actions and Decisions</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.187416</td>\n",
       "      <td>197.85</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[Minister angry about ojol holiday bonus, Offi...</td>\n",
       "      <td>2.119606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Indonesia's Foreign Policy</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.541693</td>\n",
       "      <td>245.92</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[Indonesia responds to Trump's import tariffs,...</td>\n",
       "      <td>2.233157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             unified_issue  \\\n",
       "0              Prabowo's Domestic Policies   \n",
       "1             Economic Issues and Policies   \n",
       "2        Prabowo's Speeches and Statements   \n",
       "3        Prabowo's International Relations   \n",
       "4     Prabowo's Leadership and Performance   \n",
       "5             Gaza Conflict and Evacuation   \n",
       "6               Indonesia-Turkey Relations   \n",
       "7             Public Opinion and Reactions   \n",
       "8        Political Dynamics and Coalitions   \n",
       "9                    Business and Industry   \n",
       "10                    Lebaran and Security   \n",
       "11                  Titiek Puspa's Passing   \n",
       "12              Trump's Tariffs and Impact   \n",
       "13             Education and Social Issues   \n",
       "14              Civil Society and Advocacy   \n",
       "15             Legal and Regulatory Issues   \n",
       "16               Corruption and Governance   \n",
       "17               Indonesia's Food Security   \n",
       "18               Transportation and Safety   \n",
       "19                    Koperasi Merah Putih   \n",
       "20                    Security and Defense   \n",
       "21  Presidential Transition and Leadership   \n",
       "22                    Regional Development   \n",
       "23           Student Activism and Movement   \n",
       "24                 Media and Communication   \n",
       "25       Family and Personal Relationships   \n",
       "26              Housing and Infrastructure   \n",
       "27               Hoaxes and Misinformation   \n",
       "28                  Willie Salim's Charity   \n",
       "29   Indonesia U17 World Cup Qualification   \n",
       "30                   Cultural Preservation   \n",
       "31              Hajj and Religious Affairs   \n",
       "32           Natural Disasters and Impacts   \n",
       "33                 Tourism and Hospitality   \n",
       "34       Ministerial Actions and Decisions   \n",
       "35              Indonesia's Foreign Policy   \n",
       "\n",
       "                                          description  \\\n",
       "0   This category covers discussions and news rela...   \n",
       "1   This category encompasses discussions and news...   \n",
       "2   This category focuses on analyzing Prabowo's p...   \n",
       "3   This category covers discussions and news rela...   \n",
       "4   This category analyzes Prabowo's leadership st...   \n",
       "5   This category covers discussions and news rela...   \n",
       "6   This category focuses on discussions and news ...   \n",
       "7   This category analyzes public opinion and reac...   \n",
       "8   This category covers discussions and news rela...   \n",
       "9   This category covers discussions and news rela...   \n",
       "10  This category covers discussions and news rela...   \n",
       "11  This category covers discussions and news rela...   \n",
       "12  This category covers discussions and news rela...   \n",
       "13  This category covers discussions and news rela...   \n",
       "14  This category covers discussions and news rela...   \n",
       "15  This category covers discussions and news rela...   \n",
       "16  This category covers discussions and news rela...   \n",
       "17  This category covers discussions and news rela...   \n",
       "18  This category covers discussions and news rela...   \n",
       "19  This category covers discussions and news rela...   \n",
       "20  This category covers discussions and news rela...   \n",
       "21  This category covers discussions and news rela...   \n",
       "22  This category covers discussions and news rela...   \n",
       "23  This category covers discussions and news rela...   \n",
       "24  This category covers discussions and news rela...   \n",
       "25  This category covers discussions and news rela...   \n",
       "26  This category covers discussions and news rela...   \n",
       "27  This category covers discussions and news rela...   \n",
       "28  This category covers discussions and news rela...   \n",
       "29  This category covers discussions and news rela...   \n",
       "30  This category covers discussions and news rela...   \n",
       "31  This category covers discussions and news rela...   \n",
       "32  This category covers discussions and news rela...   \n",
       "33  This category covers discussions and news rela...   \n",
       "34  This category covers discussions and news rela...   \n",
       "35  This category covers discussions and news rela...   \n",
       "\n",
       "                                sentiment_description  total_posts  \\\n",
       "0   This category reflects a predominantly positiv...        214.0   \n",
       "1   This category reflects a mixed sentiment towar...        344.0   \n",
       "2   This category reflects a generally positive se...        344.0   \n",
       "3   This category reflects a generally positive se...        247.0   \n",
       "4   This category reflects a mixed sentiment towar...        146.0   \n",
       "5   This category reflects a mixed sentiment towar...        152.0   \n",
       "6   This category reflects a positive sentiment to...        193.0   \n",
       "7   This category reflects a mixed sentiment towar...        119.0   \n",
       "8   This category reflects a dynamic and evolving ...         99.0   \n",
       "9   This category reflects a mixed sentiment towar...         73.0   \n",
       "10  This category reflects a generally positive se...         39.0   \n",
       "11  This category reflects a somber and respectful...         51.0   \n",
       "12  This category reflects a mixed sentiment towar...        109.0   \n",
       "13  This category reflects a mixed sentiment towar...         54.0   \n",
       "14  This category reflects a dynamic and evolving ...         39.0   \n",
       "15  This category reflects a mixed sentiment towar...         40.0   \n",
       "16  This category reflects a mixed sentiment towar...         26.0   \n",
       "17  This category reflects a generally positive se...         33.0   \n",
       "18  This category reflects a mixed sentiment towar...         26.0   \n",
       "19  This category reflects a generally positive se...         31.0   \n",
       "20  This category reflects a mixed sentiment towar...         27.0   \n",
       "21  This category reflects a mixed sentiment towar...         49.0   \n",
       "22  This category reflects a mixed sentiment towar...         16.0   \n",
       "23  This category reflects a mixed sentiment towar...          4.0   \n",
       "24  This category reflects a complex and evolving ...         18.0   \n",
       "25  This category reflects a mixed sentiment towar...          5.0   \n",
       "26  This category reflects a mixed sentiment towar...          2.0   \n",
       "27  This category reflects a concern about the spr...          2.0   \n",
       "28  This category reflects a generally positive se...          2.0   \n",
       "29  This category reflects a highly positive senti...          5.0   \n",
       "30  This category reflects a positive sentiment to...          8.0   \n",
       "31  This category reflects a positive sentiment to...          4.0   \n",
       "32  This category reflects a mixed sentiment towar...          4.0   \n",
       "33  This category reflects a generally positive se...          2.0   \n",
       "34  This category reflects a mixed sentiment towar...         56.0   \n",
       "35  This category reflects a mixed sentiment towar...         59.0   \n",
       "\n",
       "    viral_score  reach_score  negative  positive  neutral  \\\n",
       "0    110.649760       359.52      31.0      84.0     99.0   \n",
       "1    105.164758       789.46      86.0     112.0    146.0   \n",
       "2     94.172025       867.21      55.0     113.0    175.0   \n",
       "3     88.160128       435.64      38.0     101.0    108.0   \n",
       "4     84.120122       279.15      32.0      53.0     61.0   \n",
       "5     62.977020       244.45      43.0      38.0     71.0   \n",
       "6     59.592829       676.72       1.0     131.0     61.0   \n",
       "7     40.910934       326.80      36.0      45.0     38.0   \n",
       "8     32.429507       220.68      10.0      30.0     58.0   \n",
       "9     25.279807       132.30      25.0      28.0     20.0   \n",
       "10    21.006371        65.70       2.0      34.0      3.0   \n",
       "11    19.793880        96.05      25.0      16.0      6.0   \n",
       "12    18.541262       252.40      41.0      14.0     53.0   \n",
       "13    17.465046       111.75       3.0      39.0     12.0   \n",
       "14    13.743148        91.10      18.0      16.0      5.0   \n",
       "15    13.321629       120.40      14.0      10.0     16.0   \n",
       "16    10.930549        49.70      10.0       6.0     10.0   \n",
       "17    10.644099        57.15       0.0      30.0      3.0   \n",
       "18    10.373472        50.40       8.0      14.0      4.0   \n",
       "19     9.889393        73.20       1.0      15.0     15.0   \n",
       "20     9.785933        53.85      10.0       8.0      9.0   \n",
       "21     7.089060       166.63      10.0      12.0     27.0   \n",
       "22     2.470689        74.80       2.0      11.0      3.0   \n",
       "23     2.356881         5.45       4.0       0.0      0.0   \n",
       "24     0.780878        62.29       7.0       2.0      9.0   \n",
       "25     0.050000        47.40       2.0       0.0      3.0   \n",
       "26     0.000000         2.60       0.0       2.0      0.0   \n",
       "27     0.000000         3.50       2.0       0.0      0.0   \n",
       "28     1.058824         3.90       0.0       2.0      0.0   \n",
       "29     0.796353         7.60       0.0       5.0      0.0   \n",
       "30     2.309369        21.35       0.0       7.0      1.0   \n",
       "31     1.401450        12.70       0.0       3.0      1.0   \n",
       "32     1.303644         8.20       2.0       2.0      0.0   \n",
       "33     1.298246         2.15       0.0       1.0      1.0   \n",
       "34     9.187416       197.85      17.0      25.0     14.0   \n",
       "35     8.541693       245.92       6.0      23.0     30.0   \n",
       "\n",
       "                                           list_issue  share_of_voice  \n",
       "0   [Prabowo wants to remove import quotas, Prabow...        8.099924  \n",
       "1   [Subsidized housing for Gojek drivers, Qatar i...       13.020439  \n",
       "2   [Prabowo's nervous speech in Turkish Parliamen...       13.020439  \n",
       "3   [Prabowo voices support for Palestine in Turke...        9.348978  \n",
       "4   [Prabowo admits poor government communication,...        5.526117  \n",
       "5   [Prabowo seeks support to evacuate Gazans, Pra...        5.753217  \n",
       "6   [Turkey and Indonesia strategic partnership ag...        7.305072  \n",
       "7   [Support for Prabowo's import policy, Prabowo'...        4.504164  \n",
       "8   [PDIP remains opposition after Mega-Prabowo me...        3.747161  \n",
       "9   [Rokhmin urges stronger, competitive food sect...        2.763058  \n",
       "10  [Polri praised for managing Lebaran traffic, P...        1.476154  \n",
       "11  [Condolences for Titiek Puspa's passing, Prabo...        1.930356  \n",
       "12  [BPJS protects workers from Trump tariff impac...        4.125662  \n",
       "13  [Kemensos prepares 'Sekolah Rakyat' for SMA, V...        2.043906  \n",
       "14  [Peaceful protest faces multiple eviction atte...        1.476154  \n",
       "15  [Meikarta developers urged to compensate consu...        1.514005  \n",
       "16  [KPK supports impoverishing corruptors' famili...        0.984103  \n",
       "17  [Indonesia's food stocks strongest in 20 years...        1.249054  \n",
       "18  [Driving safety tips for long commutes, Invest...        0.984103  \n",
       "19  [ALFI supports logistics for Koperasi Merah Pu...        1.173354  \n",
       "20  [Questioning TNI authority removal in narcotic...        1.021953  \n",
       "21  [Hasan Nasbi's evaluation depends on President...        1.854656  \n",
       "22  [Papua Barat evaluates RPJMD supporting Prabow...        0.605602  \n",
       "23  [Civil resistance fragmented, student movement...        0.151400  \n",
       "24  [Journalist assaulted during Kapolri coverage,...        0.681302  \n",
       "25  [Aufaa Luqman is Almas' brother, How to perfor...        0.189251  \n",
       "26  [Subsidized housing for workers, first handove...        0.075700  \n",
       "27  [Hoax lottery registration link Bank Sumut, Ho...        0.075700  \n",
       "28  [Willie Salim cooks for 100k Bengkulu, Willie ...        0.075700  \n",
       "29  [Indonesia U17 qualifies for World Cup, Indone...        0.189251  \n",
       "30  [HB II descendants preserve ancestral culture,...        0.302801  \n",
       "31  [Kemenag Sumbar submits 5880 hajj visa documen...        0.151400  \n",
       "32  [Earthquake damages houses near Prabowo's resi...        0.151400  \n",
       "33  [Fave Hotel Banjarmasin holds kids fashion, Fa...        0.075700  \n",
       "34  [Minister angry about ojol holiday bonus, Offi...        2.119606  \n",
       "35  [Indonesia responds to Trump's import tariffs,...        2.233157  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['prabowo']\n",
    "# Hitung tanggal 120 hari ke belakang dari sekarang\n",
    "\n",
    "current_date = datetime.now()\n",
    "date_120_days_ago = current_date - timedelta(days=10)\n",
    "# Format tanggal ke format ISO 8601 yang kompatibel dengan Elasticsearch\n",
    "start_date = date_120_days_ago.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "#mendapatkan raw data\n",
    "df = pd.DataFrame(get_relevan_data(keywords,start_date))\n",
    "\n",
    "#mendapatkan dataframe aggregate per issue\n",
    "df_issue = get_df_issue(df)\n",
    "\n",
    "#chunk df_issue\n",
    "data_chunk = chunk_dataframe(df_issue, 100)\n",
    "\n",
    "#mendapatkan central issue berdasarkan viral score tertinggi\n",
    "df_central = get_central_issue(data_chunk[0])\n",
    "\n",
    "LIST_UNIFIED_ISSUE = df_central['unified_issue'].to_list()\n",
    "\n",
    "SISA = data_chunk[0][~data_chunk[0]['index'].isin([j for i in df_central['list_issue_id'] for j in i])]\n",
    "if not SISA.empty:\n",
    "    data_chunk[1] = pd.concat([data_chunk[1], SISA])\n",
    "\n",
    "\n",
    "\n",
    "#mendapatkan seluruh unified issue \n",
    "all_result = []\n",
    "for DC in tqdm(data_chunk[1:]):\n",
    "    issue_list = []\n",
    "    for idx, row in DC.iterrows():\n",
    "        issue_list.append({\"id\": row['index'], \"issue\": row['issue']})\n",
    "\n",
    "\n",
    "    df_predict = ''\n",
    "\n",
    "    while True:\n",
    "        if type(df_predict)!=str:\n",
    "            issue_list = [i for i in issue_list if i['id'] not in [j for i in df_predict['list_issue_id'] for j in i]]\n",
    "        # Buat prompt yang lebih terstruktur dan eksplisit\n",
    "        prompt = f\"\"\"\n",
    "            Kamu adalah Media Social Analyst Expert dengan keahlian dalam pengelompokan tematik dan kategorisasi konten sosial media.\n",
    "\n",
    "            # TUGAS UTAMA\n",
    "            Analisis dan kelompokkan list issue baru ke dalam kelompok tematik yang sudah ada (jika relevan) atau buat kelompok baru jika diperlukan.\n",
    "\n",
    "            # ATURAN PENGELOMPOKAN\n",
    "            1. PENTING: Prioritaskan pengelompokan ke dalam kategori yang sudah ada jika terdapat kemiripan tema.\n",
    "            2. Buat kategori baru HANYA jika issue tidak cocok dengan kelompok yang sudah ada.\n",
    "            3. Setiap issue ID HANYA boleh masuk ke SATU kelompok (mutually exclusive).\n",
    "            4. Hindari TUMPANG TINDIH issue di antara kelompok-kelompok.\n",
    "\n",
    "            # KELOMPOK YANG SUDAH ADA\n",
    "            Berikut adalah kelompok tematik yang sudah ada dan HARUS digunakan jika relevan:\n",
    "            ```\n",
    "            {LIST_UNIFIED_ISSUE}\n",
    "            ```\n",
    "\n",
    "            # LIST ISSUE YANG AKAN DIKELOMPOKKAN\n",
    "            ```\n",
    "            {issue_list}\n",
    "            ```\n",
    "\n",
    "            # PETUNJUK PENGELOMPOKAN\n",
    "            - Jika issue memiliki kemiripan SUBSTANSIAL dengan kelompok yang sudah ada → masukkan ke kelompok tersebut\n",
    "            - Jika issue SAMA SEKALI TIDAK TERKAIT dengan kelompok yang ada → buat kelompok baru\n",
    "            - Kemiripan didasarkan pada tema, topik, kata kunci, dan konteks (bukan sentimen)\n",
    "            - Usahakan untuk TIDAK membuat kelompok baru jika masih bisa dimasukkan ke kelompok yang sudah ada\n",
    "\n",
    "            # FORMAT OUTPUT (JSON)\n",
    "            [\n",
    "              {{\n",
    "                \"unified_issue\": \"Nama Issue Kelompok (gunakan dari list yang sudah ada atau buat baru)\",\n",
    "                \"description\": \"Deskripsi singkat dan jelas tentang tema kelompok ini\",\n",
    "                \"list_issue_id\": [1, 5, 10, 15] // Daftar ID issue yang masuk dalam kelompok ini\n",
    "              }},\n",
    "              ...\n",
    "            ]\n",
    "\n",
    "            # KRITERIA KUALITAS\n",
    "            - Setiap kelompok sebaiknya memiliki minimal 2 issue\n",
    "            - Nama kelompok baru harus singkat, jelas, dan deskriptif\n",
    "            - Prioritaskan penggunaan nama kelompok yang sudah ada\n",
    "            - Pastikan seluruh index issue masuk ke setiap kelompok tanpa tersisia\n",
    "\n",
    "            PENTING: Hasilkan HANYA format JSON murni tanpa komentar, penjelasan, atau notasi lain.\"\"\"\n",
    "\n",
    "        predict = call_gemini(prompt)\n",
    "        df_predict = pd.DataFrame(eval(re.findall(r'\\[.*\\]',predict, flags=re.I|re.S)[0]))\n",
    "        all_result.append(df_predict)\n",
    "\n",
    "        LIST_UNIFIED_ISSUE.extend(df_predict['unified_issue'].to_list())\n",
    "\n",
    "        LIST_UNIFIED_ISSUE = list(set(LIST_UNIFIED_ISSUE))\n",
    "\n",
    "\n",
    "        SISA = set([i['id'] for i in issue_list])- set([j for i in df_predict['list_issue_id'] for j in i])\n",
    "\n",
    "        if not SISA:\n",
    "            break\n",
    "\n",
    "all_result.append(df_central)\n",
    "topics = pd.concat(all_result)\n",
    "\n",
    "#merge dengan nama issue berdasarkan id\n",
    "all_topics = topics.groupby('unified_issue').agg({'list_issue_id':[lambda s: [j for i in s for j in i], lambda s: len([j for i in s for j in i])]}).reset_index()\n",
    "all_topics.columns = ['unified_issue','list_issue','total_issue']\n",
    "\n",
    "merge_all_topics = []\n",
    "for _,i in all_topics.iterrows():\n",
    "    data = df_issue[df_issue['index'].isin(i['list_issue'])]\n",
    "    dt = data[['total_posts','viral_score','reach_score','negative','positive','neutral']].sum().to_dict()\n",
    "    dt.update({'unified_issue':i['unified_issue'], 'list_issue':data['issue'].to_list()})\n",
    "\n",
    "    merge_all_topics.append(dt)\n",
    "\n",
    "df_all_topics = pd.DataFrame(merge_all_topics).sort_values('viral_score', ascending = False)\n",
    "\n",
    "\n",
    "\n",
    "df_all_topics['share_of_voice'] = df_all_topics['total_posts']/df_all_topics['total_posts'].sum()*100\n",
    "\n",
    "\n",
    "#ambil importance post sebagai perwakilan\n",
    "list_data = []\n",
    "for _,i in df_all_topics.iterrows():\n",
    "    unified_issue = i['unified_issue']\n",
    "    list_issue = i['list_issue']\n",
    "    list_caption = df[df['issue'].isin(list_issue)].sort_values('viral_score',ascending = False).drop_duplicates('post_caption')[:5]['post_caption'].to_list()\n",
    "\n",
    "    list_data.append({'unified_issue':unified_issue,\n",
    "                            'list_caption':list_caption,\n",
    "                      'sentiment negative':i['negative'],\n",
    "                      'sentiment positive':i['positive']})\n",
    "\n",
    "list_prediction = []\n",
    "for unified_issues_list in tqdm(chunk_list(list_data, 40)):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Kamu adalah Media Social Analyst Expert dengan keahlian dalam analisis kategori dan isu-isu sosial media.\n",
    "\n",
    "    # TUGAS\n",
    "    Buatkan deskripsi yang informatif, akurat, dan komprehensif untuk setiap kategori unified_issue berikut ini.\n",
    "\n",
    "    # PETUNJUK\n",
    "    1. Deskripsi harus menjelaskan dengan jelas apa yang termasuk dalam kategori tersebut\n",
    "    2. Deskripsi harus ringkas namun komprehensif (maksimal 2-3 kalimat)\n",
    "    3. Gunakan bahasa yang netral dan profesional\n",
    "    4. Fokus pada konten dan cakupan dari kategori isu tersebut\n",
    "    5. Jangan menyertakan opini pribadi atau bias dalam deskripsi\n",
    "    6. Berikan juga description berdasarkan sentimentnya\n",
    "\n",
    "    # DATA UNIFIED_ISSUE\n",
    "    ```\n",
    "    {unified_issues_list}\n",
    "    ```\n",
    "\n",
    "    # FORMAT OUTPUT\n",
    "    Berikan hasil dalam format JSON seperti berikut:\n",
    "    ```\n",
    "    [\n",
    "      {{\n",
    "        \"unified_issue\": \"Nama Unified Issue\",\n",
    "        \"description\": \"Deskripsi komprehensif tentang unified issue ini\"\n",
    "      }},\n",
    "      {{\n",
    "        \"unified_issue\": \"Nama Unified Issue Lainnya\",\n",
    "        \"description\": \"Deskripsi komprehensif tentang unified issue ini\"\n",
    "      }},\n",
    "      ...\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    ### HARD RULE\n",
    "    - Berikan HANYA output JSON tanpa penjelasan atau komentar tambahan.\n",
    "    - Hindari penjelasan \"This category focuses\" , contoh description yang baik seperti ini \"Conversations praised recent innovations in the nickel industry that emphasize sustainability and local economic growth, boosting positive sentiment towards Prabowo by 18%\"\n",
    "    \"\"\"\n",
    "    response_text = call_gemini(prompt)\n",
    "\n",
    "\n",
    "    try:\n",
    "        json_string = eval(re.findall(r'\\[.*\\]', response_text, flags = re.I|re.S)[0])\n",
    "    except:\n",
    "        response_text = (re.sub(f\"(?<!\\:\\s)\\\"([\\w\\s\\/\\.\\@\\-]+)\\\"(?![\\,\\:])\",r\"`\\1`\",response_text))\n",
    "\n",
    "\n",
    "        try:\n",
    "            json_string = eval(re.findall(r'\\[.*\\]', response_text, flags = re.I|re.S)[0])\n",
    "        except:\n",
    "            json_string = []\n",
    "            for i in re.findall(r'{.*?}', response_text, flags=re.I|re.S):\n",
    "                try:\n",
    "                    json_string.append(eval(i))\n",
    "                except:\n",
    "                    pass  \n",
    "\n",
    "\n",
    "    list_prediction.extend(json_string)\n",
    "\n",
    "\n",
    "topics_result = pd.DataFrame(list_prediction).merge(df_all_topics, on = 'unified_issue')\n",
    "topics_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d75f8d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:25:39.218232Z",
     "start_time": "2025-04-18T06:25:39.146000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unified_issue</th>\n",
       "      <th>description</th>\n",
       "      <th>sentiment_description</th>\n",
       "      <th>total_posts</th>\n",
       "      <th>viral_score</th>\n",
       "      <th>reach_score</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>list_issue</th>\n",
       "      <th>share_of_voice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prabowo's Domestic Policies</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a predominantly positiv...</td>\n",
       "      <td>214.0</td>\n",
       "      <td>110.649760</td>\n",
       "      <td>359.52</td>\n",
       "      <td>31.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>[Prabowo wants to remove import quotas, Prabow...</td>\n",
       "      <td>8.099924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Economic Issues and Policies</td>\n",
       "      <td>This category encompasses discussions and news...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>344.0</td>\n",
       "      <td>105.164758</td>\n",
       "      <td>789.46</td>\n",
       "      <td>86.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>[Subsidized housing for Gojek drivers, Qatar i...</td>\n",
       "      <td>13.020439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prabowo's Speeches and Statements</td>\n",
       "      <td>This category focuses on analyzing Prabowo's p...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>344.0</td>\n",
       "      <td>94.172025</td>\n",
       "      <td>867.21</td>\n",
       "      <td>55.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>[Prabowo's nervous speech in Turkish Parliamen...</td>\n",
       "      <td>13.020439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prabowo's International Relations</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>247.0</td>\n",
       "      <td>88.160128</td>\n",
       "      <td>435.64</td>\n",
       "      <td>38.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>[Prabowo voices support for Palestine in Turke...</td>\n",
       "      <td>9.348978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prabowo's Leadership and Performance</td>\n",
       "      <td>This category analyzes Prabowo's leadership st...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>146.0</td>\n",
       "      <td>84.120122</td>\n",
       "      <td>279.15</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>[Prabowo admits poor government communication,...</td>\n",
       "      <td>5.526117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gaza Conflict and Evacuation</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>62.977020</td>\n",
       "      <td>244.45</td>\n",
       "      <td>43.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>[Prabowo seeks support to evacuate Gazans, Pra...</td>\n",
       "      <td>5.753217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Indonesia-Turkey Relations</td>\n",
       "      <td>This category focuses on discussions and news ...</td>\n",
       "      <td>This category reflects a positive sentiment to...</td>\n",
       "      <td>193.0</td>\n",
       "      <td>59.592829</td>\n",
       "      <td>676.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>[Turkey and Indonesia strategic partnership ag...</td>\n",
       "      <td>7.305072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Public Opinion and Reactions</td>\n",
       "      <td>This category analyzes public opinion and reac...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>40.910934</td>\n",
       "      <td>326.80</td>\n",
       "      <td>36.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>[Support for Prabowo's import policy, Prabowo'...</td>\n",
       "      <td>4.504164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Political Dynamics and Coalitions</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a dynamic and evolving ...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>32.429507</td>\n",
       "      <td>220.68</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>[PDIP remains opposition after Mega-Prabowo me...</td>\n",
       "      <td>3.747161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business and Industry</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>25.279807</td>\n",
       "      <td>132.30</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[Rokhmin urges stronger, competitive food sect...</td>\n",
       "      <td>2.763058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lebaran and Security</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.006371</td>\n",
       "      <td>65.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Polri praised for managing Lebaran traffic, P...</td>\n",
       "      <td>1.476154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Titiek Puspa's Passing</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a somber and respectful...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.793880</td>\n",
       "      <td>96.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[Condolences for Titiek Puspa's passing, Prabo...</td>\n",
       "      <td>1.930356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Trump's Tariffs and Impact</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>18.541262</td>\n",
       "      <td>252.40</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>[BPJS protects workers from Trump tariff impac...</td>\n",
       "      <td>4.125662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Education and Social Issues</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>17.465046</td>\n",
       "      <td>111.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[Kemensos prepares 'Sekolah Rakyat' for SMA, V...</td>\n",
       "      <td>2.043906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Civil Society and Advocacy</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a dynamic and evolving ...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.743148</td>\n",
       "      <td>91.10</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Peaceful protest faces multiple eviction atte...</td>\n",
       "      <td>1.476154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Legal and Regulatory Issues</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13.321629</td>\n",
       "      <td>120.40</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[Meikarta developers urged to compensate consu...</td>\n",
       "      <td>1.514005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Corruption and Governance</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.930549</td>\n",
       "      <td>49.70</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[KPK supports impoverishing corruptors' famili...</td>\n",
       "      <td>0.984103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Indonesia's Food Security</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.644099</td>\n",
       "      <td>57.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Indonesia's food stocks strongest in 20 years...</td>\n",
       "      <td>1.249054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Transportation and Safety</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.373472</td>\n",
       "      <td>50.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Driving safety tips for long commutes, Invest...</td>\n",
       "      <td>0.984103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Koperasi Merah Putih</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>9.889393</td>\n",
       "      <td>73.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[ALFI supports logistics for Koperasi Merah Pu...</td>\n",
       "      <td>1.173354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Security and Defense</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.785933</td>\n",
       "      <td>53.85</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[Questioning TNI authority removal in narcotic...</td>\n",
       "      <td>1.021953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Presidential Transition and Leadership</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.089060</td>\n",
       "      <td>166.63</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>[Hasan Nasbi's evaluation depends on President...</td>\n",
       "      <td>1.854656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Regional Development</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.470689</td>\n",
       "      <td>74.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Papua Barat evaluates RPJMD supporting Prabow...</td>\n",
       "      <td>0.605602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Student Activism and Movement</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.356881</td>\n",
       "      <td>5.45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Civil resistance fragmented, student movement...</td>\n",
       "      <td>0.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Media and Communication</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a complex and evolving ...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.780878</td>\n",
       "      <td>62.29</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[Journalist assaulted during Kapolri coverage,...</td>\n",
       "      <td>0.681302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Family and Personal Relationships</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>47.40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Aufaa Luqman is Almas' brother, How to perfor...</td>\n",
       "      <td>0.189251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Housing and Infrastructure</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Subsidized housing for workers, first handove...</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hoaxes and Misinformation</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a concern about the spr...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Hoax lottery registration link Bank Sumut, Ho...</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Willie Salim's Charity</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Willie Salim cooks for 100k Bengkulu, Willie ...</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Indonesia U17 World Cup Qualification</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a highly positive senti...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.796353</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Indonesia U17 qualifies for World Cup, Indone...</td>\n",
       "      <td>0.189251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cultural Preservation</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a positive sentiment to...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.309369</td>\n",
       "      <td>21.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[HB II descendants preserve ancestral culture,...</td>\n",
       "      <td>0.302801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hajj and Religious Affairs</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a positive sentiment to...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.401450</td>\n",
       "      <td>12.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Kemenag Sumbar submits 5880 hajj visa documen...</td>\n",
       "      <td>0.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Natural Disasters and Impacts</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.303644</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Earthquake damages houses near Prabowo's resi...</td>\n",
       "      <td>0.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tourism and Hospitality</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a generally positive se...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.298246</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fave Hotel Banjarmasin holds kids fashion, Fa...</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ministerial Actions and Decisions</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.187416</td>\n",
       "      <td>197.85</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[Minister angry about ojol holiday bonus, Offi...</td>\n",
       "      <td>2.119606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Indonesia's Foreign Policy</td>\n",
       "      <td>This category covers discussions and news rela...</td>\n",
       "      <td>This category reflects a mixed sentiment towar...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.541693</td>\n",
       "      <td>245.92</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[Indonesia responds to Trump's import tariffs,...</td>\n",
       "      <td>2.233157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             unified_issue  \\\n",
       "0              Prabowo's Domestic Policies   \n",
       "1             Economic Issues and Policies   \n",
       "2        Prabowo's Speeches and Statements   \n",
       "3        Prabowo's International Relations   \n",
       "4     Prabowo's Leadership and Performance   \n",
       "5             Gaza Conflict and Evacuation   \n",
       "6               Indonesia-Turkey Relations   \n",
       "7             Public Opinion and Reactions   \n",
       "8        Political Dynamics and Coalitions   \n",
       "9                    Business and Industry   \n",
       "10                    Lebaran and Security   \n",
       "11                  Titiek Puspa's Passing   \n",
       "12              Trump's Tariffs and Impact   \n",
       "13             Education and Social Issues   \n",
       "14              Civil Society and Advocacy   \n",
       "15             Legal and Regulatory Issues   \n",
       "16               Corruption and Governance   \n",
       "17               Indonesia's Food Security   \n",
       "18               Transportation and Safety   \n",
       "19                    Koperasi Merah Putih   \n",
       "20                    Security and Defense   \n",
       "21  Presidential Transition and Leadership   \n",
       "22                    Regional Development   \n",
       "23           Student Activism and Movement   \n",
       "24                 Media and Communication   \n",
       "25       Family and Personal Relationships   \n",
       "26              Housing and Infrastructure   \n",
       "27               Hoaxes and Misinformation   \n",
       "28                  Willie Salim's Charity   \n",
       "29   Indonesia U17 World Cup Qualification   \n",
       "30                   Cultural Preservation   \n",
       "31              Hajj and Religious Affairs   \n",
       "32           Natural Disasters and Impacts   \n",
       "33                 Tourism and Hospitality   \n",
       "34       Ministerial Actions and Decisions   \n",
       "35              Indonesia's Foreign Policy   \n",
       "\n",
       "                                          description  \\\n",
       "0   This category covers discussions and news rela...   \n",
       "1   This category encompasses discussions and news...   \n",
       "2   This category focuses on analyzing Prabowo's p...   \n",
       "3   This category covers discussions and news rela...   \n",
       "4   This category analyzes Prabowo's leadership st...   \n",
       "5   This category covers discussions and news rela...   \n",
       "6   This category focuses on discussions and news ...   \n",
       "7   This category analyzes public opinion and reac...   \n",
       "8   This category covers discussions and news rela...   \n",
       "9   This category covers discussions and news rela...   \n",
       "10  This category covers discussions and news rela...   \n",
       "11  This category covers discussions and news rela...   \n",
       "12  This category covers discussions and news rela...   \n",
       "13  This category covers discussions and news rela...   \n",
       "14  This category covers discussions and news rela...   \n",
       "15  This category covers discussions and news rela...   \n",
       "16  This category covers discussions and news rela...   \n",
       "17  This category covers discussions and news rela...   \n",
       "18  This category covers discussions and news rela...   \n",
       "19  This category covers discussions and news rela...   \n",
       "20  This category covers discussions and news rela...   \n",
       "21  This category covers discussions and news rela...   \n",
       "22  This category covers discussions and news rela...   \n",
       "23  This category covers discussions and news rela...   \n",
       "24  This category covers discussions and news rela...   \n",
       "25  This category covers discussions and news rela...   \n",
       "26  This category covers discussions and news rela...   \n",
       "27  This category covers discussions and news rela...   \n",
       "28  This category covers discussions and news rela...   \n",
       "29  This category covers discussions and news rela...   \n",
       "30  This category covers discussions and news rela...   \n",
       "31  This category covers discussions and news rela...   \n",
       "32  This category covers discussions and news rela...   \n",
       "33  This category covers discussions and news rela...   \n",
       "34  This category covers discussions and news rela...   \n",
       "35  This category covers discussions and news rela...   \n",
       "\n",
       "                                sentiment_description  total_posts  \\\n",
       "0   This category reflects a predominantly positiv...        214.0   \n",
       "1   This category reflects a mixed sentiment towar...        344.0   \n",
       "2   This category reflects a generally positive se...        344.0   \n",
       "3   This category reflects a generally positive se...        247.0   \n",
       "4   This category reflects a mixed sentiment towar...        146.0   \n",
       "5   This category reflects a mixed sentiment towar...        152.0   \n",
       "6   This category reflects a positive sentiment to...        193.0   \n",
       "7   This category reflects a mixed sentiment towar...        119.0   \n",
       "8   This category reflects a dynamic and evolving ...         99.0   \n",
       "9   This category reflects a mixed sentiment towar...         73.0   \n",
       "10  This category reflects a generally positive se...         39.0   \n",
       "11  This category reflects a somber and respectful...         51.0   \n",
       "12  This category reflects a mixed sentiment towar...        109.0   \n",
       "13  This category reflects a mixed sentiment towar...         54.0   \n",
       "14  This category reflects a dynamic and evolving ...         39.0   \n",
       "15  This category reflects a mixed sentiment towar...         40.0   \n",
       "16  This category reflects a mixed sentiment towar...         26.0   \n",
       "17  This category reflects a generally positive se...         33.0   \n",
       "18  This category reflects a mixed sentiment towar...         26.0   \n",
       "19  This category reflects a generally positive se...         31.0   \n",
       "20  This category reflects a mixed sentiment towar...         27.0   \n",
       "21  This category reflects a mixed sentiment towar...         49.0   \n",
       "22  This category reflects a mixed sentiment towar...         16.0   \n",
       "23  This category reflects a mixed sentiment towar...          4.0   \n",
       "24  This category reflects a complex and evolving ...         18.0   \n",
       "25  This category reflects a mixed sentiment towar...          5.0   \n",
       "26  This category reflects a mixed sentiment towar...          2.0   \n",
       "27  This category reflects a concern about the spr...          2.0   \n",
       "28  This category reflects a generally positive se...          2.0   \n",
       "29  This category reflects a highly positive senti...          5.0   \n",
       "30  This category reflects a positive sentiment to...          8.0   \n",
       "31  This category reflects a positive sentiment to...          4.0   \n",
       "32  This category reflects a mixed sentiment towar...          4.0   \n",
       "33  This category reflects a generally positive se...          2.0   \n",
       "34  This category reflects a mixed sentiment towar...         56.0   \n",
       "35  This category reflects a mixed sentiment towar...         59.0   \n",
       "\n",
       "    viral_score  reach_score  negative  positive  neutral  \\\n",
       "0    110.649760       359.52      31.0      84.0     99.0   \n",
       "1    105.164758       789.46      86.0     112.0    146.0   \n",
       "2     94.172025       867.21      55.0     113.0    175.0   \n",
       "3     88.160128       435.64      38.0     101.0    108.0   \n",
       "4     84.120122       279.15      32.0      53.0     61.0   \n",
       "5     62.977020       244.45      43.0      38.0     71.0   \n",
       "6     59.592829       676.72       1.0     131.0     61.0   \n",
       "7     40.910934       326.80      36.0      45.0     38.0   \n",
       "8     32.429507       220.68      10.0      30.0     58.0   \n",
       "9     25.279807       132.30      25.0      28.0     20.0   \n",
       "10    21.006371        65.70       2.0      34.0      3.0   \n",
       "11    19.793880        96.05      25.0      16.0      6.0   \n",
       "12    18.541262       252.40      41.0      14.0     53.0   \n",
       "13    17.465046       111.75       3.0      39.0     12.0   \n",
       "14    13.743148        91.10      18.0      16.0      5.0   \n",
       "15    13.321629       120.40      14.0      10.0     16.0   \n",
       "16    10.930549        49.70      10.0       6.0     10.0   \n",
       "17    10.644099        57.15       0.0      30.0      3.0   \n",
       "18    10.373472        50.40       8.0      14.0      4.0   \n",
       "19     9.889393        73.20       1.0      15.0     15.0   \n",
       "20     9.785933        53.85      10.0       8.0      9.0   \n",
       "21     7.089060       166.63      10.0      12.0     27.0   \n",
       "22     2.470689        74.80       2.0      11.0      3.0   \n",
       "23     2.356881         5.45       4.0       0.0      0.0   \n",
       "24     0.780878        62.29       7.0       2.0      9.0   \n",
       "25     0.050000        47.40       2.0       0.0      3.0   \n",
       "26     0.000000         2.60       0.0       2.0      0.0   \n",
       "27     0.000000         3.50       2.0       0.0      0.0   \n",
       "28     1.058824         3.90       0.0       2.0      0.0   \n",
       "29     0.796353         7.60       0.0       5.0      0.0   \n",
       "30     2.309369        21.35       0.0       7.0      1.0   \n",
       "31     1.401450        12.70       0.0       3.0      1.0   \n",
       "32     1.303644         8.20       2.0       2.0      0.0   \n",
       "33     1.298246         2.15       0.0       1.0      1.0   \n",
       "34     9.187416       197.85      17.0      25.0     14.0   \n",
       "35     8.541693       245.92       6.0      23.0     30.0   \n",
       "\n",
       "                                           list_issue  share_of_voice  \n",
       "0   [Prabowo wants to remove import quotas, Prabow...        8.099924  \n",
       "1   [Subsidized housing for Gojek drivers, Qatar i...       13.020439  \n",
       "2   [Prabowo's nervous speech in Turkish Parliamen...       13.020439  \n",
       "3   [Prabowo voices support for Palestine in Turke...        9.348978  \n",
       "4   [Prabowo admits poor government communication,...        5.526117  \n",
       "5   [Prabowo seeks support to evacuate Gazans, Pra...        5.753217  \n",
       "6   [Turkey and Indonesia strategic partnership ag...        7.305072  \n",
       "7   [Support for Prabowo's import policy, Prabowo'...        4.504164  \n",
       "8   [PDIP remains opposition after Mega-Prabowo me...        3.747161  \n",
       "9   [Rokhmin urges stronger, competitive food sect...        2.763058  \n",
       "10  [Polri praised for managing Lebaran traffic, P...        1.476154  \n",
       "11  [Condolences for Titiek Puspa's passing, Prabo...        1.930356  \n",
       "12  [BPJS protects workers from Trump tariff impac...        4.125662  \n",
       "13  [Kemensos prepares 'Sekolah Rakyat' for SMA, V...        2.043906  \n",
       "14  [Peaceful protest faces multiple eviction atte...        1.476154  \n",
       "15  [Meikarta developers urged to compensate consu...        1.514005  \n",
       "16  [KPK supports impoverishing corruptors' famili...        0.984103  \n",
       "17  [Indonesia's food stocks strongest in 20 years...        1.249054  \n",
       "18  [Driving safety tips for long commutes, Invest...        0.984103  \n",
       "19  [ALFI supports logistics for Koperasi Merah Pu...        1.173354  \n",
       "20  [Questioning TNI authority removal in narcotic...        1.021953  \n",
       "21  [Hasan Nasbi's evaluation depends on President...        1.854656  \n",
       "22  [Papua Barat evaluates RPJMD supporting Prabow...        0.605602  \n",
       "23  [Civil resistance fragmented, student movement...        0.151400  \n",
       "24  [Journalist assaulted during Kapolri coverage,...        0.681302  \n",
       "25  [Aufaa Luqman is Almas' brother, How to perfor...        0.189251  \n",
       "26  [Subsidized housing for workers, first handove...        0.075700  \n",
       "27  [Hoax lottery registration link Bank Sumut, Ho...        0.075700  \n",
       "28  [Willie Salim cooks for 100k Bengkulu, Willie ...        0.075700  \n",
       "29  [Indonesia U17 qualifies for World Cup, Indone...        0.189251  \n",
       "30  [HB II descendants preserve ancestral culture,...        0.302801  \n",
       "31  [Kemenag Sumbar submits 5880 hajj visa documen...        0.151400  \n",
       "32  [Earthquake damages houses near Prabowo's resi...        0.151400  \n",
       "33  [Fave Hotel Banjarmasin holds kids fashion, Fa...        0.075700  \n",
       "34  [Minister angry about ojol holiday bonus, Offi...        2.119606  \n",
       "35  [Indonesia responds to Trump's import tariffs,...        2.233157  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f5c0165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:24:38.438252Z",
     "start_time": "2025-04-18T06:24:38.425667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unified_issue', 'description', 'total_posts', 'viral_score',\n",
       "       'reach_score', 'negative', 'positive', 'neutral', 'list_issue',\n",
       "       'share_of_voice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hasil).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f317641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f01736d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:27:51.272549Z",
     "start_time": "2025-04-18T06:27:51.260547Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_relevan_data(keywords,start_date=None, size = 10000 ):\n",
    "    current_date = datetime.now()\n",
    "    if not start_date:\n",
    "        # Hitung tanggal 120 hari ke belakang dari sekarang\n",
    "        \n",
    "        date_120_days_ago = current_date - timedelta(days=120)\n",
    "        # Format tanggal ke format ISO 8601 yang kompatibel dengan Elasticsearch\n",
    "        start_date = date_120_days_ago.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    es_helper = ElasticsearchHelper(host=\"http://localhost:9200\")\n",
    "    query = {\n",
    "        \"_source\": [\"issue\", \"post_caption\", \"reach_score\", \"viral_score\", \"sentiment\", \"link_post\", \"channel\"],\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"post_caption\": {\n",
    "                                \"query\": keyword,\n",
    "                                \"operator\": \"and\"  # Semua kata dalam keyword harus ada\n",
    "                            }\n",
    "                        }\n",
    "                    } for keyword in keywords\n",
    "                ],\n",
    "              \"must\": [\n",
    "                            {\n",
    "                                \"range\": {\n",
    "                                    \"post_created_at\": {\n",
    "                                        \"gte\": start_date,  # Greater than or equal to 120 hari yang lalu\n",
    "                                        \"lte\": current_date.strftime(\"%Y-%m-%d %H:%M:%S\")  # Less than or equal to sekarang\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                \"must_not\": [\n",
    "                    {\n",
    "                        \"match\": {\n",
    "                            \"issue\": \"Not Specified\"  # Filter: 'issue' tidak boleh \"Not Specified\"\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"minimum_should_match\": 1  # Minimal satu keyword yang cocok\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return es_helper.fetch_data(index=\"twitter_data,linkedin_data,news_data,reddit_data,youtube_data\",\n",
    "                                query=query, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d9d0b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:28:17.993980Z",
     "start_time": "2025-04-18T06:28:14.674935Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_relevan_data(['ruu tni'],size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecc6ac4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T06:28:34.445211Z",
     "start_time": "2025-04-18T06:28:34.434698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38a166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "906c88e8",
   "metadata": {},
   "source": [
    "# KOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd7d21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T04:30:36.727403Z",
     "start_time": "2025-04-18T04:30:36.546549Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((((((((((((((((((((( MASUK ))))))))))))))))))))))\n",
      "Successfully connected to http://localhost:9200\n",
      "Successfully connected to http://localhost:9200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_user</th>\n",
       "      <th>link_post</th>\n",
       "      <th>viral_score</th>\n",
       "      <th>reach_score</th>\n",
       "      <th>channel</th>\n",
       "      <th>username</th>\n",
       "      <th>issue</th>\n",
       "      <th>user_category</th>\n",
       "      <th>user_influence_score</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>is_negative_driver</th>\n",
       "      <th>unified_issue</th>\n",
       "      <th>share_of_voice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://x.com/DJ_Luvly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>twitter</td>\n",
       "      <td>@DJ_Luvly</td>\n",
       "      <td>[Comparing current regime to ORBA era]</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.8771</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[Political Analysis and Commentary]</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://x.com/Wan_2045</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>twitter</td>\n",
       "      <td>@Wan_2045</td>\n",
       "      <td>[PDIP's inconsistent stance and potential Prab...</td>\n",
       "      <td>human</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[Megawati Soekarnoputri's Activities]</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://x.com/itsurboihyl</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>twitter</td>\n",
       "      <td>@itsurboihyl</td>\n",
       "      <td>[Allegations of political alliances]</td>\n",
       "      <td>human</td>\n",
       "      <td>0.4984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[Prabowo Subianto's Activities]</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://x.com/janetez69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>twitter</td>\n",
       "      <td>@janetez69</td>\n",
       "      <td>[PDIP is held hostage by Jokowi and Luhut]</td>\n",
       "      <td>Buzzer</td>\n",
       "      <td>0.1722</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[Megawati Soekarnoputri's Activities]</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://x.com/sdmgvn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>twitter</td>\n",
       "      <td>@sdmgvn</td>\n",
       "      <td>[PDIP's political strategy]</td>\n",
       "      <td>Human</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[PDIP Internal Affairs]</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   link_user  link_post  viral_score  reach_score  channel  \\\n",
       "0     https://x.com/DJ_Luvly          1          0.0         0.18  twitter   \n",
       "1     https://x.com/Wan_2045          1          0.0         0.00  twitter   \n",
       "2  https://x.com/itsurboihyl          1          0.0         0.75  twitter   \n",
       "3    https://x.com/janetez69          1          0.0         0.00  twitter   \n",
       "4       https://x.com/sdmgvn          1          0.0         0.00  twitter   \n",
       "\n",
       "       username                                              issue  \\\n",
       "0     @DJ_Luvly             [Comparing current regime to ORBA era]   \n",
       "1     @Wan_2045  [PDIP's inconsistent stance and potential Prab...   \n",
       "2  @itsurboihyl               [Allegations of political alliances]   \n",
       "3    @janetez69         [PDIP is held hostage by Jokowi and Luhut]   \n",
       "4       @sdmgvn                        [PDIP's political strategy]   \n",
       "\n",
       "  user_category  user_influence_score  sentiment_negative  sentiment_positive  \\\n",
       "0         Human                0.8771                   1                   0   \n",
       "1         human                0.0168                   1                   0   \n",
       "2         human                0.4984                   1                   0   \n",
       "3        Buzzer                0.1722                   1                   0   \n",
       "4         Human                0.0364                   1                   0   \n",
       "\n",
       "   sentiment_neutral  is_negative_driver  \\\n",
       "0                  0                True   \n",
       "1                  0                True   \n",
       "2                  0                True   \n",
       "3                  0                True   \n",
       "4                  0                True   \n",
       "\n",
       "                           unified_issue  share_of_voice  \n",
       "0    [Political Analysis and Commentary]            20.0  \n",
       "1  [Megawati Soekarnoputri's Activities]            20.0  \n",
       "2        [Prabowo Subianto's Activities]            20.0  \n",
       "3  [Megawati Soekarnoputri's Activities]            20.0  \n",
       "4                [PDIP Internal Affairs]            20.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.kol_overview import search_kol\n",
    "\n",
    "hasil = search_kol(  \n",
    "    owner_id = '5',\n",
    "    project_name = \"gibran raka\",\n",
    "    es_host=None,\n",
    "    keywords=[\"pdip\"],sentiment=['negative'])\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(hasil).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab41c7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T05:48:35.694679Z",
     "start_time": "2025-04-18T05:48:29.806913Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26140\\1543774683.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'final_result' is not defined"
     ]
    }
   ],
   "source": [
    "final_result"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
